{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ladder Training.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/legendaryuchiha/Ladder-Training-Pytorch-Auto-Encoders-/blob/master/Ladder_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "7c8u56FeKbMh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "d81a6ff7-47fc-43e9-d8ef-0b1e41fa0b64"
      },
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd import Function\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 519.5MB 27kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x5851a000 @  0x7fdffe7602a4 0x594e17 0x626104 0x51190a 0x4f5277 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x4f3338 0x510fb0 0x5119bd 0x4f6070\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "Successfully installed torch-0.4.1\n",
            "Collecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 2.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.4.1)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 12.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Installing collected packages: pillow, torchvision\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.3.0 torchvision-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RlG_9gZ3KvqG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Getting The Libraries **"
      ]
    },
    {
      "metadata": {
        "id": "M02x1BPZK0mJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd import Function\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xjN4UxLYLGhG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Loading the Dataset **"
      ]
    },
    {
      "metadata": {
        "id": "a-1HZe3ZLNgG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "e9a5a126-95ea-4838-e4b2-6945154c8616"
      },
      "cell_type": "code",
      "source": [
        "BatchSize = 1024\n",
        "trainset = torchvision.datasets.MNIST(root='./MNIST', train=True,download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BatchSize,shuffle=True) \n",
        "testset = torchvision.datasets.MNIST(root='./MNIST', train=False,download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BatchSize,shuffle=False) \n",
        "classes = ('zero', 'one', 'two', 'three','four', 'five', 'six', 'seven', 'eight', 'nine')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kzr9HgDwMJiM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Autoencoder**"
      ]
    },
    {
      "metadata": {
        "id": "54VErfBqMND_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(nn.Linear(28*28, 400),nn.Tanh())\n",
        "        self.decoder = nn.Sequential(nn.Linear(400, 28*28),nn.Sigmoid())\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "model=autoencoder()\n",
        "model=model.double()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YFhGDQu4NKY6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Train Model**"
      ]
    },
    {
      "metadata": {
        "id": "34hEuudsNZ2Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "iterations = 20\n",
        "learning_rate = 0.01\n",
        "optimizer=optim.SGD(model.parameters(),lr=learning_rate,momentum=0.9)\n",
        "criteria = nn.MSELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4OOSnfKtQOvG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "70952123-219c-45c6-b5f4-48a114e67d14"
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(iterations):  # Training epochs\n",
        "    runningLoss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs = Variable(inputs.view(-1, 28*28).double()) #Converting them into Variable\n",
        "        # Training and updating the weights\n",
        "        model.zero_grad()  \n",
        "        outputs = model(inputs) \n",
        "        loss = criteria(outputs, inputs) \n",
        "        loss.backward() \n",
        "        optimizer.step()\n",
        "        runningLoss += loss.data[0]\n",
        "        \n",
        "    print('At Iteration : %d / %d  ;  Mean-Squared Error : %f'%(epoch + 1,iterations,runningLoss/(60000/BatchSize)))\n",
        "print('Finished Training')"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.231486\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.225937\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.219528\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.211722\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.202094\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.190600\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.177654\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.163981\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.150505\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.138011\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.126987\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.117634\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 0.109878\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 0.103550\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 0.098410\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 0.094250\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 0.090847\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 0.088054\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 0.085760\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 0.083839\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PABctS43QiZz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "e622ff03-c129-4cf9-8011-a0755fec5ce1"
      },
      "cell_type": "code",
      "source": [
        "model.add_module('Encoder_Layer',nn.Sequential(nn.Linear(400,512),nn.Tanh()))\n",
        "model.add_module('Decoder layer',nn.Sequential(nn.Linear(512,400),nn.Tanh()))\n",
        "model.double()\n",
        "print(model)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "autoencoder(\n",
            "  (encoder): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=400, bias=True)\n",
            "    (1): Tanh()\n",
            "  )\n",
            "  (decoder): Sequential(\n",
            "    (0): Linear(in_features=400, out_features=784, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            "  (Encoder_Layer): Sequential(\n",
            "    (0): Linear(in_features=400, out_features=512, bias=True)\n",
            "    (1): Tanh()\n",
            "  )\n",
            "  (Decoder layer): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=400, bias=True)\n",
            "    (1): Tanh()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "415aqLZJRSQP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 20471
        },
        "outputId": "da198376-c5a7-453d-c559-b06def532203"
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(iterations):\n",
        "  for i,data in enumerate(trainloader,0):\n",
        "    inputs, labels = data\n",
        "    inputs = Variable(inputs.view(-1, 28*28).double())\n",
        "    model.zero_grad()  \n",
        "    outputs = model(inputs) \n",
        "    loss = criteria(outputs, inputs) \n",
        "    loss.backward() \n",
        "    optimizer.step()\n",
        "    runningLoss += loss.data[0]\n",
        "        \n",
        "    print('At Iteration : %d / %d  ;  Mean-Squared Error : %f'%(epoch + 1,iterations,runningLoss/(60000/BatchSize)))\n",
        "print('Finished Training')"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.085255\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.086645\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.088052\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.089465\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.090860\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.092265\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.093670\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.095070\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.096481\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.097885\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.099282\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.100690\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.102078\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.103489\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.104897\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.106295\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.107698\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.109109\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.110509\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.111905\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.113303\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.114688\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.116077\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.117479\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.118867\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.120270\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.121663\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.123064\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.124450\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.125849\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.127239\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.128622\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.130016\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.131402\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.132796\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.134187\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.135590\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.136980\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.138366\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.139754\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.141147\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.142528\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.143913\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.145290\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.146673\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.148061\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.149443\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.150821\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.152208\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.153591\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.154980\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.156360\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.157739\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.159125\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.160510\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.161888\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.163284\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.164668\n",
            "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.166063\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.167451\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.168850\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.170229\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.171605\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.172978\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.174353\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.175732\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.177095\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.178459\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.179841\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.181240\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.182627\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.183999\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.185367\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.186744\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.188117\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.189485\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.190860\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.192248\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.193625\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.195003\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.196380\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.197753\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.199126\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.200497\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.201863\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.203239\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.204606\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.205966\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.207333\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.208692\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.210068\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.211440\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.212812\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.214167\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.215529\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.216905\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.218261\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.219626\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.220985\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.222355\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.223719\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.225078\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.226447\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.227814\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.229190\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.230562\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.231925\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.233284\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.234642\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.236009\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.237367\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.238739\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.240104\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.241463\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.242830\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.244178\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.245542\n",
            "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.246918\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.248280\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.249637\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.250999\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.252358\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.253708\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.255074\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.256431\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.257790\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.259151\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.260503\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.261850\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.263206\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.264558\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.265920\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.267256\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.268615\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.269968\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.271324\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.272665\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.274026\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.275380\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.276733\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.278089\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.279439\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.280794\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.282139\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.283499\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.284842\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.286193\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.287538\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.288887\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.290250\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.291602\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.292960\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.294306\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.295648\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.297002\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.298345\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.299699\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.301053\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.302402\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.303745\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.305100\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.306438\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.307783\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.309117\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.310461\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.311815\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.313170\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.314519\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.315861\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.317202\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.318547\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.319895\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.321238\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.322580\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.323921\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.325255\n",
            "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.326595\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.327941\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.329279\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.330630\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.331980\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.333322\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.334650\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.335981\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.337333\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.338679\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.340022\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.341368\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.342713\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.344047\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.345380\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.346715\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.348048\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.349386\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.350736\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.352067\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.353404\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.354740\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.356085\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.357428\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.358763\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.360089\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.361428\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.362757\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.364090\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.365430\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.366765\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.368096\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.369424\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.370753\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.372086\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.373408\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.374749\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.376071\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.377396\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.378724\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.380048\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.381385\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.382711\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.384045\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.385387\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.386715\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.388045\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.389369\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.390695\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.392020\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.393334\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.394659\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.395983\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.397306\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.398634\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.399968\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.401293\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.402606\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.403940\n",
            "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.405262\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.406592\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.407920\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.409239\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.410565\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.411896\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.413219\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.414538\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.415861\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.417168\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.418477\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.419800\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.421118\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.422445\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.423777\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.425096\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.426413\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.427740\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.429067\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.430392\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.431720\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.433059\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.434379\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.435700\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.437022\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.438341\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.439654\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.440971\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.442288\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.443605\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.444919\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.446230\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.447549\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.448864\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.450193\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.451502\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.452811\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.454132\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.455448\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.456770\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.458087\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.459408\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.460711\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.462043\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.463346\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.464666\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.465984\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.467314\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.468622\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.469931\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.471236\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.472562\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.473874\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.475196\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.476497\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.477802\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.479108\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.480417\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.481739\n",
            "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.483055\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.484369\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.485666\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.486981\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.488306\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.489628\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.490933\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.492230\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.493538\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.494833\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.496148\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.497465\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.498782\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.500091\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.501398\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.502706\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.504027\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.505336\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.506653\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.507956\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.509264\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.510565\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.511879\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.513179\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.514499\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.515808\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.517118\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.518412\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.519713\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.521023\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.522340\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.523640\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.524939\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.526229\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.527539\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.528853\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.530152\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.531438\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.532745\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.534065\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.535361\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.536657\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.537966\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.539267\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.540566\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.541869\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.543181\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.544482\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.545783\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.547080\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.548386\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.549680\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.550985\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.552293\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.553587\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.554883\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.556192\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.557483\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.558781\n",
            "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.560081\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.561379\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.562679\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.563968\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.565252\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.566543\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.567845\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.569142\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.570442\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.571752\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.573067\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.574360\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.575661\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.576968\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.578264\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.579569\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.580870\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.582170\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.583482\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.584764\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.586053\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.587344\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.588634\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.589939\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.591237\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.592526\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.593822\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.595120\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.596398\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.597676\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.598975\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.600264\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.601560\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.602860\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.604167\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.605460\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.606768\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.608052\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.609344\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.610632\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.611933\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.613230\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.614523\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.615808\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.617095\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.618389\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.619681\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.620973\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.622259\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.623540\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.624837\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.626136\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.627423\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.628694\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.629977\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.631275\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.632563\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.633857\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.635145\n",
            "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.636428\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.637723\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.639014\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.640298\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.641588\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.642866\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.644144\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.645425\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.646715\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.648004\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.649303\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.650593\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.651872\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.653162\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.654447\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.655723\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.657008\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.658285\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.659571\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.660863\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.662138\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.663423\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.664714\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.665995\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.667281\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.668551\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.669844\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.671113\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.672399\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.673697\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.674976\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.676251\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.677519\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.678811\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.680094\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.681373\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.682658\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.683929\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.685221\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.686512\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.687784\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.689080\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.690373\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.691659\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.692949\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.694234\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.695522\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.696799\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.698078\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.699366\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.700667\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.701949\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.703225\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.704509\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.705779\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.707053\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.708332\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.709623\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.710896\n",
            "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.712182\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.713445\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.714733\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.716011\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.717289\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.718562\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.719842\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.721136\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.722400\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.723679\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.724955\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.726228\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.727512\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.728789\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.730066\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.731332\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.732609\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.733882\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.735147\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.736419\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.737698\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.738987\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.740262\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.741535\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.742820\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.744079\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.745367\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.746628\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.747905\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.749185\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.750465\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.751741\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.753015\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.754292\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.755565\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.756827\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.758101\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.759373\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.760651\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.761927\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.763195\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.764470\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.765757\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.767033\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.768305\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.769575\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.770859\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.772135\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.773413\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.774680\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.775941\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.777215\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.778505\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.779781\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.781062\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.782337\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.783614\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.784878\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.786133\n",
            "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.787397\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.788673\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.789943\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.791222\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.792480\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.793746\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.795013\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.796269\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.797531\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.798805\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.800087\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.801355\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.802618\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.803889\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.805156\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.806424\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.807680\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.808940\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.810185\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.811460\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.812733\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.813999\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.815276\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.816550\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.817823\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.819080\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.820365\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.821619\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.822882\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.824167\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.825437\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.826700\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.827983\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.829235\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.830508\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.831783\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.833059\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.834338\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.835614\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.836875\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.838136\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.839382\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.840643\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.841907\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.843185\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.844443\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.845720\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.846976\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.848246\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.849514\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.850775\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.852041\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.853307\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.854572\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.855834\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.857097\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.858350\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.859617\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.860874\n",
            "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.862133\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.863397\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.864668\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.865939\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.867204\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.868457\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.869719\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.870981\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.872240\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.873508\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.874767\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.876038\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.877301\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.878563\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.879813\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.881072\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.882317\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.883585\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.884844\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.886112\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.887367\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.888622\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.889895\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.891155\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.892413\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.893668\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.894930\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.896194\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.897457\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.898704\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.899956\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.901213\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.902463\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.903729\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.904980\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.906247\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.907505\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.908773\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.910029\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.911273\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.912531\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.913790\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.915040\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.916305\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.917569\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.918840\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.920083\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.921342\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.922618\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.923872\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.925135\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.926397\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.927641\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.928904\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.930160\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.931415\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.932682\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.933938\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.935180\n",
            "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.936441\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.937695\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.938961\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.940223\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.941469\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.942742\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.943987\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.945247\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.946502\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.947755\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.949018\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.950267\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.951512\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.952777\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.954033\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.955297\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.956552\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.957799\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.959041\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.960291\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.961547\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.962787\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.964040\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.965283\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.966541\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.967793\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.969035\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.970304\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.971557\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.972803\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.974050\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.975316\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.976576\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.977825\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.979070\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.980328\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.981581\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.982831\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.984087\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.985352\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.986600\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.987838\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.989078\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.990334\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.991592\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.992858\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.994129\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.995372\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.996626\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.997878\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.999135\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 1.000388\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 1.001617\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 1.002857\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 1.004113\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 1.005357\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 1.006601\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 1.007842\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 1.009103\n",
            "At Iteration : 12 / 20  ;  Mean-Squared Error : 1.010358\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.011607\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.012851\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.014099\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.015344\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.016582\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.017843\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.019098\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.020361\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.021613\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.022870\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.024115\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.025354\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.026605\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.027856\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.029090\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.030337\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.031582\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.032824\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.034071\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.035323\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.036577\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.037831\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.039072\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.040318\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.041554\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.042799\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.044034\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.045272\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.046501\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.047745\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.049005\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.050255\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.051489\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.052756\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.053999\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.055237\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.056490\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.057733\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.058986\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.060232\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.061483\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.062732\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.063980\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.065226\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.066469\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.067707\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.068963\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.070221\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.071472\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.072707\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.073959\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.075209\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.076455\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.077690\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.078934\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.080180\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.081414\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.082661\n",
            "At Iteration : 13 / 20  ;  Mean-Squared Error : 1.083925\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.085166\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.086413\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.087657\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.088909\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.090161\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.091410\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.092648\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.093898\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.095138\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.096381\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.097618\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.098859\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.100110\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.101347\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.102589\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.103838\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.105068\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.106294\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.107517\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.108753\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.109984\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.111221\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.112466\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.113691\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.114931\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.116183\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.117438\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.118682\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.119918\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.121154\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.122383\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.123624\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.124854\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.126118\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.127342\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.128583\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.129827\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.131058\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.132311\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.133549\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.134783\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.136029\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.137283\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.138523\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.139760\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.141029\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.142275\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.143505\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.144738\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.145982\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.147223\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.148471\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.149717\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.150966\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.152201\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.153452\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.154693\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.155931\n",
            "At Iteration : 14 / 20  ;  Mean-Squared Error : 1.157148\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.158385\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.159630\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.160870\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.162101\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.163333\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.164575\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.165805\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.167042\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.168281\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.169516\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.170761\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.172002\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.173254\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.174479\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.175710\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.176953\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.178186\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.179409\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.180653\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.181877\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.183129\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.184364\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.185604\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.186834\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.188076\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.189312\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.190529\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.191769\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.192995\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.194228\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.195464\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.196705\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.197950\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.199192\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.200427\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.201660\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.202886\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.204114\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.205345\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.206572\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.207808\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.209045\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.210282\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.211516\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.212749\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.213984\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.215237\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.216472\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.217717\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.218956\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.220189\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.221429\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.222650\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.223896\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.225128\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.226376\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.227606\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.228841\n",
            "At Iteration : 15 / 20  ;  Mean-Squared Error : 1.230085\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.231321\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.232568\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.233798\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.235027\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.236265\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.237486\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.238701\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.239920\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.241135\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.242364\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.243606\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.244847\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.246072\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.247301\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.248530\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.249777\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.251010\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.252230\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.253461\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.254685\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.255924\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.257158\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.258385\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.259612\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.260849\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.262078\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.263309\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.264553\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.265787\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.267025\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.268252\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.269478\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.270714\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.271956\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.273193\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.274431\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.275655\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.276882\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.278106\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.279327\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.280541\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.281787\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.283009\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.284238\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.285478\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.286703\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.287953\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.289190\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.290410\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.291638\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.292864\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.294106\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.295336\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.296573\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.297782\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.299034\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.300264\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.301511\n",
            "At Iteration : 16 / 20  ;  Mean-Squared Error : 1.302743\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.303971\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.305195\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.306427\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.307661\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.308894\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.310119\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.311354\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.312577\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.313804\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.315028\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.316266\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.317485\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.318708\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.319942\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.321165\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.322396\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.323622\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.324849\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.326082\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.327304\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.328523\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.329755\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.330987\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.332206\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.333439\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.334671\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.335894\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.337133\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.338374\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.339601\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.340838\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.342068\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.343295\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.344521\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.345745\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.346974\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.348207\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.349433\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.350674\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.351905\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.353119\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.354356\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.355567\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.356802\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.358027\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.359243\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.360462\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.361693\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.362912\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.364124\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.365347\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.366569\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.367790\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.369015\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.370239\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.371472\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.372693\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.373926\n",
            "At Iteration : 17 / 20  ;  Mean-Squared Error : 1.375139\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.376365\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.377591\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.378826\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.380054\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.381301\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.382519\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.383740\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.384971\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.386200\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.387421\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.388638\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.389856\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.391082\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.392309\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.393542\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.394765\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.395987\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.397216\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.398445\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.399670\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.400890\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.402104\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.403315\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.404561\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.405784\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.407001\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.408207\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.409435\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.410659\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.411887\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.413105\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.414307\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.415526\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.416760\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.417996\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.419226\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.420451\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.421667\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.422880\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.424103\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.425322\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.426547\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.427774\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.428997\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.430203\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.431429\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.432651\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.433861\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.435078\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.436312\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.437529\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.438746\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.439971\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.441184\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.442410\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.443638\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.444845\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.446075\n",
            "At Iteration : 18 / 20  ;  Mean-Squared Error : 1.447307\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.448529\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.449755\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.450995\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.452218\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.453442\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.454670\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.455901\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.457139\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.458349\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.459567\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.460778\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.461993\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.463229\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.464453\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.465683\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.466899\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.468117\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.469338\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.470567\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.471781\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.472993\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.474215\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.475435\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.476656\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.477872\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.479088\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.480311\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.481529\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.482746\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.483968\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.485190\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.486412\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.487649\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.488857\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.490076\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.491304\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.492528\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.493734\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.494949\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.496163\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.497386\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.498605\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.499811\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.501033\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.502259\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.503480\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.504672\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.505874\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.507105\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.508324\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.509539\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.510739\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.511959\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.513178\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.514390\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.515615\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.516829\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.518039\n",
            "At Iteration : 19 / 20  ;  Mean-Squared Error : 1.519244\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.520461\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.521668\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.522894\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.524124\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.525346\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.526566\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.527786\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.528991\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.530214\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.531431\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.532650\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.533863\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.535082\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.536310\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.537540\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.538751\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.539965\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.541192\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.542407\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.543625\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.544841\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.546078\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.547297\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.548520\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.549726\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.550960\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.552168\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.553378\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.554588\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.555809\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.557027\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.558242\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.559462\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.560679\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.561895\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.563104\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.564317\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.565536\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.566743\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.567950\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.569175\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.570402\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.571611\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.572820\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.574043\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.575257\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.576466\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.577676\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.578881\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.580096\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.581313\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.582526\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.583726\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.584939\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.586148\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.587364\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.588561\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.589767\n",
            "At Iteration : 20 / 20  ;  Mean-Squared Error : 1.590979\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_QAalg6ET60E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**`Adding the Classifier and Removing both Decoder Units`**"
      ]
    },
    {
      "metadata": {
        "id": "DogIMnk3AmlV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "outputId": "e428253d-5ebb-441a-8da0-bebc1ab37c00"
      },
      "cell_type": "code",
      "source": [
        "classifier = nn.Sequential(*list(model.children())[0:1])\n",
        "classifier.add_module('2nd layer',nn.Sequential(*list(model.children())[2]))\n",
        "model =classifier\n",
        "model.add_module('classifier', nn.Sequential(nn.Linear(512, 10),nn.LogSoftmax()))\n",
        "print(model)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=400, bias=True)\n",
            "    (1): Tanh()\n",
            "  )\n",
            "  (2nd layer): Sequential(\n",
            "    (0): Linear(in_features=400, out_features=512, bias=True)\n",
            "    (1): Tanh()\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (1): LogSoftmax()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BdhbDYq-3r39",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "outputId": "d1eb7fd8-5fa2-418a-8984-92f71e0deb4a"
      },
      "cell_type": "code",
      "source": [
        "print(model)\n",
        "model.double()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=400, bias=True)\n",
            "    (1): Tanh()\n",
            "  )\n",
            "  (2nd layer): Sequential(\n",
            "    (0): Linear(in_features=400, out_features=512, bias=True)\n",
            "    (1): Tanh()\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (1): LogSoftmax()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=400, bias=True)\n",
              "    (1): Tanh()\n",
              "  )\n",
              "  (2nd layer): Sequential(\n",
              "    (0): Linear(in_features=400, out_features=512, bias=True)\n",
              "    (1): Tanh()\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=10, bias=True)\n",
              "    (1): LogSoftmax()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "metadata": {
        "id": "efAmM1Y2mkeC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Final Training**"
      ]
    },
    {
      "metadata": {
        "id": "_06dNyFzU5nG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 15669
        },
        "outputId": "ec0042cc-09d4-4209-a97b-950d10eecb80"
      },
      "cell_type": "code",
      "source": [
        "criteria =nn.NLLLoss()\n",
        "iterations=30\n",
        "for epoch in range(iterations):\n",
        "  runningLoss = 0.0\n",
        "  for i,data in enumerate(trainloader,0):\n",
        "    inputs, labels = data\n",
        "    inputs = Variable(inputs.view(-1, 28*28).double())\n",
        "    labels=Variable(labels)\n",
        "    model.zero_grad()  \n",
        "    outputs = model(inputs) \n",
        "    loss = criteria(outputs, labels) \n",
        "    loss.backward() \n",
        "    optimizer.step()\n",
        "    runningLoss += loss.data[0]\n",
        "    correct = 0\n",
        "    total = 0\n",
        "  for data in testloader:\n",
        "    inputs, labels = data\n",
        "    inputs = Variable(inputs.view(-1, 28*28).double())\n",
        "    labels=Variable(labels)\n",
        "    outputs = model(inputs)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum()\n",
        "    print('At Iteration : %d / %d  ;  Train Error : %f ;Test Accuracy : %f'%(epoch + 1,iterations,runningLoss/(60000/BatchSize),100 * correct /float(total)))\n",
        "        \n",
        "    print('At Iteration : %d / %d  ; Loss : %f'%(epoch + 1,iterations,runningLoss/(60000/BatchSize)))\n",
        "print('Done!!')"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:91: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "At Iteration : 1 / 45  ;  Train Error : 2.271573 ;Test Accuracy : 42.000000\n",
            "At Iteration : 1 / 45  ; Loss : 2.271573\n",
            "At Iteration : 1 / 45  ;  Train Error : 2.271573 ;Test Accuracy : 40.000000\n",
            "At Iteration : 1 / 45  ; Loss : 2.271573\n",
            "At Iteration : 1 / 45  ;  Train Error : 2.271573 ;Test Accuracy : 40.000000\n",
            "At Iteration : 1 / 45  ; Loss : 2.271573\n",
            "At Iteration : 1 / 45  ;  Train Error : 2.271573 ;Test Accuracy : 40.000000\n",
            "At Iteration : 1 / 45  ; Loss : 2.271573\n",
            "At Iteration : 1 / 45  ;  Train Error : 2.271573 ;Test Accuracy : 40.000000\n",
            "At Iteration : 1 / 45  ; Loss : 2.271573\n",
            "At Iteration : 1 / 45  ;  Train Error : 2.271573 ;Test Accuracy : 41.000000\n",
            "At Iteration : 1 / 45  ; Loss : 2.271573\n",
            "At Iteration : 1 / 45  ;  Train Error : 2.271573 ;Test Accuracy : 41.000000\n",
            "At Iteration : 1 / 45  ; Loss : 2.271573\n",
            "At Iteration : 1 / 45  ;  Train Error : 2.271573 ;Test Accuracy : 41.000000\n",
            "At Iteration : 1 / 45  ; Loss : 2.271573\n",
            "At Iteration : 1 / 45  ;  Train Error : 2.271573 ;Test Accuracy : 41.000000\n",
            "At Iteration : 1 / 45  ; Loss : 2.271573\n",
            "At Iteration : 1 / 45  ;  Train Error : 2.271573 ;Test Accuracy : 41.000000\n",
            "At Iteration : 1 / 45  ; Loss : 2.271573\n",
            "At Iteration : 2 / 45  ;  Train Error : 2.081167 ;Test Accuracy : 66.000000\n",
            "At Iteration : 2 / 45  ; Loss : 2.081167\n",
            "At Iteration : 2 / 45  ;  Train Error : 2.081167 ;Test Accuracy : 65.000000\n",
            "At Iteration : 2 / 45  ; Loss : 2.081167\n",
            "At Iteration : 2 / 45  ;  Train Error : 2.081167 ;Test Accuracy : 66.000000\n",
            "At Iteration : 2 / 45  ; Loss : 2.081167\n",
            "At Iteration : 2 / 45  ;  Train Error : 2.081167 ;Test Accuracy : 65.000000\n",
            "At Iteration : 2 / 45  ; Loss : 2.081167\n",
            "At Iteration : 2 / 45  ;  Train Error : 2.081167 ;Test Accuracy : 66.000000\n",
            "At Iteration : 2 / 45  ; Loss : 2.081167\n",
            "At Iteration : 2 / 45  ;  Train Error : 2.081167 ;Test Accuracy : 67.000000\n",
            "At Iteration : 2 / 45  ; Loss : 2.081167\n",
            "At Iteration : 2 / 45  ;  Train Error : 2.081167 ;Test Accuracy : 68.000000\n",
            "At Iteration : 2 / 45  ; Loss : 2.081167\n",
            "At Iteration : 2 / 45  ;  Train Error : 2.081167 ;Test Accuracy : 69.000000\n",
            "At Iteration : 2 / 45  ; Loss : 2.081167\n",
            "At Iteration : 2 / 45  ;  Train Error : 2.081167 ;Test Accuracy : 70.000000\n",
            "At Iteration : 2 / 45  ; Loss : 2.081167\n",
            "At Iteration : 2 / 45  ;  Train Error : 2.081167 ;Test Accuracy : 70.000000\n",
            "At Iteration : 2 / 45  ; Loss : 2.081167\n",
            "At Iteration : 3 / 45  ;  Train Error : 1.884611 ;Test Accuracy : 68.000000\n",
            "At Iteration : 3 / 45  ; Loss : 1.884611\n",
            "At Iteration : 3 / 45  ;  Train Error : 1.884611 ;Test Accuracy : 68.000000\n",
            "At Iteration : 3 / 45  ; Loss : 1.884611\n",
            "At Iteration : 3 / 45  ;  Train Error : 1.884611 ;Test Accuracy : 68.000000\n",
            "At Iteration : 3 / 45  ; Loss : 1.884611\n",
            "At Iteration : 3 / 45  ;  Train Error : 1.884611 ;Test Accuracy : 68.000000\n",
            "At Iteration : 3 / 45  ; Loss : 1.884611\n",
            "At Iteration : 3 / 45  ;  Train Error : 1.884611 ;Test Accuracy : 68.000000\n",
            "At Iteration : 3 / 45  ; Loss : 1.884611\n",
            "At Iteration : 3 / 45  ;  Train Error : 1.884611 ;Test Accuracy : 69.000000\n",
            "At Iteration : 3 / 45  ; Loss : 1.884611\n",
            "At Iteration : 3 / 45  ;  Train Error : 1.884611 ;Test Accuracy : 71.000000\n",
            "At Iteration : 3 / 45  ; Loss : 1.884611\n",
            "At Iteration : 3 / 45  ;  Train Error : 1.884611 ;Test Accuracy : 71.000000\n",
            "At Iteration : 3 / 45  ; Loss : 1.884611\n",
            "At Iteration : 3 / 45  ;  Train Error : 1.884611 ;Test Accuracy : 73.000000\n",
            "At Iteration : 3 / 45  ; Loss : 1.884611\n",
            "At Iteration : 3 / 45  ;  Train Error : 1.884611 ;Test Accuracy : 73.000000\n",
            "At Iteration : 3 / 45  ; Loss : 1.884611\n",
            "At Iteration : 4 / 45  ;  Train Error : 1.701861 ;Test Accuracy : 70.000000\n",
            "At Iteration : 4 / 45  ; Loss : 1.701861\n",
            "At Iteration : 4 / 45  ;  Train Error : 1.701861 ;Test Accuracy : 70.000000\n",
            "At Iteration : 4 / 45  ; Loss : 1.701861\n",
            "At Iteration : 4 / 45  ;  Train Error : 1.701861 ;Test Accuracy : 70.000000\n",
            "At Iteration : 4 / 45  ; Loss : 1.701861\n",
            "At Iteration : 4 / 45  ;  Train Error : 1.701861 ;Test Accuracy : 70.000000\n",
            "At Iteration : 4 / 45  ; Loss : 1.701861\n",
            "At Iteration : 4 / 45  ;  Train Error : 1.701861 ;Test Accuracy : 70.000000\n",
            "At Iteration : 4 / 45  ; Loss : 1.701861\n",
            "At Iteration : 4 / 45  ;  Train Error : 1.701861 ;Test Accuracy : 71.000000\n",
            "At Iteration : 4 / 45  ; Loss : 1.701861\n",
            "At Iteration : 4 / 45  ;  Train Error : 1.701861 ;Test Accuracy : 72.000000\n",
            "At Iteration : 4 / 45  ; Loss : 1.701861\n",
            "At Iteration : 4 / 45  ;  Train Error : 1.701861 ;Test Accuracy : 73.000000\n",
            "At Iteration : 4 / 45  ; Loss : 1.701861\n",
            "At Iteration : 4 / 45  ;  Train Error : 1.701861 ;Test Accuracy : 74.000000\n",
            "At Iteration : 4 / 45  ; Loss : 1.701861\n",
            "At Iteration : 4 / 45  ;  Train Error : 1.701861 ;Test Accuracy : 74.000000\n",
            "At Iteration : 4 / 45  ; Loss : 1.701861\n",
            "At Iteration : 5 / 45  ;  Train Error : 1.548301 ;Test Accuracy : 73.000000\n",
            "At Iteration : 5 / 45  ; Loss : 1.548301\n",
            "At Iteration : 5 / 45  ;  Train Error : 1.548301 ;Test Accuracy : 72.000000\n",
            "At Iteration : 5 / 45  ; Loss : 1.548301\n",
            "At Iteration : 5 / 45  ;  Train Error : 1.548301 ;Test Accuracy : 72.000000\n",
            "At Iteration : 5 / 45  ; Loss : 1.548301\n",
            "At Iteration : 5 / 45  ;  Train Error : 1.548301 ;Test Accuracy : 72.000000\n",
            "At Iteration : 5 / 45  ; Loss : 1.548301\n",
            "At Iteration : 5 / 45  ;  Train Error : 1.548301 ;Test Accuracy : 72.000000\n",
            "At Iteration : 5 / 45  ; Loss : 1.548301\n",
            "At Iteration : 5 / 45  ;  Train Error : 1.548301 ;Test Accuracy : 73.000000\n",
            "At Iteration : 5 / 45  ; Loss : 1.548301\n",
            "At Iteration : 5 / 45  ;  Train Error : 1.548301 ;Test Accuracy : 74.000000\n",
            "At Iteration : 5 / 45  ; Loss : 1.548301\n",
            "At Iteration : 5 / 45  ;  Train Error : 1.548301 ;Test Accuracy : 75.000000\n",
            "At Iteration : 5 / 45  ; Loss : 1.548301\n",
            "At Iteration : 5 / 45  ;  Train Error : 1.548301 ;Test Accuracy : 76.000000\n",
            "At Iteration : 5 / 45  ; Loss : 1.548301\n",
            "At Iteration : 5 / 45  ;  Train Error : 1.548301 ;Test Accuracy : 76.000000\n",
            "At Iteration : 5 / 45  ; Loss : 1.548301\n",
            "At Iteration : 6 / 45  ;  Train Error : 1.425959 ;Test Accuracy : 75.000000\n",
            "At Iteration : 6 / 45  ; Loss : 1.425959\n",
            "At Iteration : 6 / 45  ;  Train Error : 1.425959 ;Test Accuracy : 73.000000\n",
            "At Iteration : 6 / 45  ; Loss : 1.425959\n",
            "At Iteration : 6 / 45  ;  Train Error : 1.425959 ;Test Accuracy : 74.000000\n",
            "At Iteration : 6 / 45  ; Loss : 1.425959\n",
            "At Iteration : 6 / 45  ;  Train Error : 1.425959 ;Test Accuracy : 73.000000\n",
            "At Iteration : 6 / 45  ; Loss : 1.425959\n",
            "At Iteration : 6 / 45  ;  Train Error : 1.425959 ;Test Accuracy : 74.000000\n",
            "At Iteration : 6 / 45  ; Loss : 1.425959\n",
            "At Iteration : 6 / 45  ;  Train Error : 1.425959 ;Test Accuracy : 75.000000\n",
            "At Iteration : 6 / 45  ; Loss : 1.425959\n",
            "At Iteration : 6 / 45  ;  Train Error : 1.425959 ;Test Accuracy : 76.000000\n",
            "At Iteration : 6 / 45  ; Loss : 1.425959\n",
            "At Iteration : 6 / 45  ;  Train Error : 1.425959 ;Test Accuracy : 77.000000\n",
            "At Iteration : 6 / 45  ; Loss : 1.425959\n",
            "At Iteration : 6 / 45  ;  Train Error : 1.425959 ;Test Accuracy : 78.000000\n",
            "At Iteration : 6 / 45  ; Loss : 1.425959\n",
            "At Iteration : 6 / 45  ;  Train Error : 1.425959 ;Test Accuracy : 78.000000\n",
            "At Iteration : 6 / 45  ; Loss : 1.425959\n",
            "At Iteration : 7 / 45  ;  Train Error : 1.326934 ;Test Accuracy : 77.000000\n",
            "At Iteration : 7 / 45  ; Loss : 1.326934\n",
            "At Iteration : 7 / 45  ;  Train Error : 1.326934 ;Test Accuracy : 75.000000\n",
            "At Iteration : 7 / 45  ; Loss : 1.326934\n",
            "At Iteration : 7 / 45  ;  Train Error : 1.326934 ;Test Accuracy : 76.000000\n",
            "At Iteration : 7 / 45  ; Loss : 1.326934\n",
            "At Iteration : 7 / 45  ;  Train Error : 1.326934 ;Test Accuracy : 75.000000\n",
            "At Iteration : 7 / 45  ; Loss : 1.326934\n",
            "At Iteration : 7 / 45  ;  Train Error : 1.326934 ;Test Accuracy : 75.000000\n",
            "At Iteration : 7 / 45  ; Loss : 1.326934\n",
            "At Iteration : 7 / 45  ;  Train Error : 1.326934 ;Test Accuracy : 77.000000\n",
            "At Iteration : 7 / 45  ; Loss : 1.326934\n",
            "At Iteration : 7 / 45  ;  Train Error : 1.326934 ;Test Accuracy : 78.000000\n",
            "At Iteration : 7 / 45  ; Loss : 1.326934\n",
            "At Iteration : 7 / 45  ;  Train Error : 1.326934 ;Test Accuracy : 79.000000\n",
            "At Iteration : 7 / 45  ; Loss : 1.326934\n",
            "At Iteration : 7 / 45  ;  Train Error : 1.326934 ;Test Accuracy : 80.000000\n",
            "At Iteration : 7 / 45  ; Loss : 1.326934\n",
            "At Iteration : 7 / 45  ;  Train Error : 1.326934 ;Test Accuracy : 80.000000\n",
            "At Iteration : 7 / 45  ; Loss : 1.326934\n",
            "At Iteration : 8 / 45  ;  Train Error : 1.249217 ;Test Accuracy : 78.000000\n",
            "At Iteration : 8 / 45  ; Loss : 1.249217\n",
            "At Iteration : 8 / 45  ;  Train Error : 1.249217 ;Test Accuracy : 77.000000\n",
            "At Iteration : 8 / 45  ; Loss : 1.249217\n",
            "At Iteration : 8 / 45  ;  Train Error : 1.249217 ;Test Accuracy : 77.000000\n",
            "At Iteration : 8 / 45  ; Loss : 1.249217\n",
            "At Iteration : 8 / 45  ;  Train Error : 1.249217 ;Test Accuracy : 76.000000\n",
            "At Iteration : 8 / 45  ; Loss : 1.249217\n",
            "At Iteration : 8 / 45  ;  Train Error : 1.249217 ;Test Accuracy : 77.000000\n",
            "At Iteration : 8 / 45  ; Loss : 1.249217\n",
            "At Iteration : 8 / 45  ;  Train Error : 1.249217 ;Test Accuracy : 78.000000\n",
            "At Iteration : 8 / 45  ; Loss : 1.249217\n",
            "At Iteration : 8 / 45  ;  Train Error : 1.249217 ;Test Accuracy : 79.000000\n",
            "At Iteration : 8 / 45  ; Loss : 1.249217\n",
            "At Iteration : 8 / 45  ;  Train Error : 1.249217 ;Test Accuracy : 80.000000\n",
            "At Iteration : 8 / 45  ; Loss : 1.249217\n",
            "At Iteration : 8 / 45  ;  Train Error : 1.249217 ;Test Accuracy : 81.000000\n",
            "At Iteration : 8 / 45  ; Loss : 1.249217\n",
            "At Iteration : 8 / 45  ;  Train Error : 1.249217 ;Test Accuracy : 81.000000\n",
            "At Iteration : 8 / 45  ; Loss : 1.249217\n",
            "At Iteration : 9 / 45  ;  Train Error : 1.188835 ;Test Accuracy : 79.000000\n",
            "At Iteration : 9 / 45  ; Loss : 1.188835\n",
            "At Iteration : 9 / 45  ;  Train Error : 1.188835 ;Test Accuracy : 78.000000\n",
            "At Iteration : 9 / 45  ; Loss : 1.188835\n",
            "At Iteration : 9 / 45  ;  Train Error : 1.188835 ;Test Accuracy : 78.000000\n",
            "At Iteration : 9 / 45  ; Loss : 1.188835\n",
            "At Iteration : 9 / 45  ;  Train Error : 1.188835 ;Test Accuracy : 77.000000\n",
            "At Iteration : 9 / 45  ; Loss : 1.188835\n",
            "At Iteration : 9 / 45  ;  Train Error : 1.188835 ;Test Accuracy : 77.000000\n",
            "At Iteration : 9 / 45  ; Loss : 1.188835\n",
            "At Iteration : 9 / 45  ;  Train Error : 1.188835 ;Test Accuracy : 79.000000\n",
            "At Iteration : 9 / 45  ; Loss : 1.188835\n",
            "At Iteration : 9 / 45  ;  Train Error : 1.188835 ;Test Accuracy : 80.000000\n",
            "At Iteration : 9 / 45  ; Loss : 1.188835\n",
            "At Iteration : 9 / 45  ;  Train Error : 1.188835 ;Test Accuracy : 80.000000\n",
            "At Iteration : 9 / 45  ; Loss : 1.188835\n",
            "At Iteration : 9 / 45  ;  Train Error : 1.188835 ;Test Accuracy : 81.000000\n",
            "At Iteration : 9 / 45  ; Loss : 1.188835\n",
            "At Iteration : 9 / 45  ;  Train Error : 1.188835 ;Test Accuracy : 82.000000\n",
            "At Iteration : 9 / 45  ; Loss : 1.188835\n",
            "At Iteration : 10 / 45  ;  Train Error : 1.140175 ;Test Accuracy : 79.000000\n",
            "At Iteration : 10 / 45  ; Loss : 1.140175\n",
            "At Iteration : 10 / 45  ;  Train Error : 1.140175 ;Test Accuracy : 78.000000\n",
            "At Iteration : 10 / 45  ; Loss : 1.140175\n",
            "At Iteration : 10 / 45  ;  Train Error : 1.140175 ;Test Accuracy : 78.000000\n",
            "At Iteration : 10 / 45  ; Loss : 1.140175\n",
            "At Iteration : 10 / 45  ;  Train Error : 1.140175 ;Test Accuracy : 78.000000\n",
            "At Iteration : 10 / 45  ; Loss : 1.140175\n",
            "At Iteration : 10 / 45  ;  Train Error : 1.140175 ;Test Accuracy : 78.000000\n",
            "At Iteration : 10 / 45  ; Loss : 1.140175\n",
            "At Iteration : 10 / 45  ;  Train Error : 1.140175 ;Test Accuracy : 79.000000\n",
            "At Iteration : 10 / 45  ; Loss : 1.140175\n",
            "At Iteration : 10 / 45  ;  Train Error : 1.140175 ;Test Accuracy : 80.000000\n",
            "At Iteration : 10 / 45  ; Loss : 1.140175\n",
            "At Iteration : 10 / 45  ;  Train Error : 1.140175 ;Test Accuracy : 81.000000\n",
            "At Iteration : 10 / 45  ; Loss : 1.140175\n",
            "At Iteration : 10 / 45  ;  Train Error : 1.140175 ;Test Accuracy : 82.000000\n",
            "At Iteration : 10 / 45  ; Loss : 1.140175\n",
            "At Iteration : 10 / 45  ;  Train Error : 1.140175 ;Test Accuracy : 82.000000\n",
            "At Iteration : 10 / 45  ; Loss : 1.140175\n",
            "At Iteration : 11 / 45  ;  Train Error : 1.100318 ;Test Accuracy : 80.000000\n",
            "At Iteration : 11 / 45  ; Loss : 1.100318\n",
            "At Iteration : 11 / 45  ;  Train Error : 1.100318 ;Test Accuracy : 79.000000\n",
            "At Iteration : 11 / 45  ; Loss : 1.100318\n",
            "At Iteration : 11 / 45  ;  Train Error : 1.100318 ;Test Accuracy : 79.000000\n",
            "At Iteration : 11 / 45  ; Loss : 1.100318\n",
            "At Iteration : 11 / 45  ;  Train Error : 1.100318 ;Test Accuracy : 78.000000\n",
            "At Iteration : 11 / 45  ; Loss : 1.100318\n",
            "At Iteration : 11 / 45  ;  Train Error : 1.100318 ;Test Accuracy : 79.000000\n",
            "At Iteration : 11 / 45  ; Loss : 1.100318\n",
            "At Iteration : 11 / 45  ;  Train Error : 1.100318 ;Test Accuracy : 80.000000\n",
            "At Iteration : 11 / 45  ; Loss : 1.100318\n",
            "At Iteration : 11 / 45  ;  Train Error : 1.100318 ;Test Accuracy : 81.000000\n",
            "At Iteration : 11 / 45  ; Loss : 1.100318\n",
            "At Iteration : 11 / 45  ;  Train Error : 1.100318 ;Test Accuracy : 82.000000\n",
            "At Iteration : 11 / 45  ; Loss : 1.100318\n",
            "At Iteration : 11 / 45  ;  Train Error : 1.100318 ;Test Accuracy : 83.000000\n",
            "At Iteration : 11 / 45  ; Loss : 1.100318\n",
            "At Iteration : 11 / 45  ;  Train Error : 1.100318 ;Test Accuracy : 83.000000\n",
            "At Iteration : 11 / 45  ; Loss : 1.100318\n",
            "At Iteration : 12 / 45  ;  Train Error : 1.065913 ;Test Accuracy : 80.000000\n",
            "At Iteration : 12 / 45  ; Loss : 1.065913\n",
            "At Iteration : 12 / 45  ;  Train Error : 1.065913 ;Test Accuracy : 79.000000\n",
            "At Iteration : 12 / 45  ; Loss : 1.065913\n",
            "At Iteration : 12 / 45  ;  Train Error : 1.065913 ;Test Accuracy : 79.000000\n",
            "At Iteration : 12 / 45  ; Loss : 1.065913\n",
            "At Iteration : 12 / 45  ;  Train Error : 1.065913 ;Test Accuracy : 79.000000\n",
            "At Iteration : 12 / 45  ; Loss : 1.065913\n",
            "At Iteration : 12 / 45  ;  Train Error : 1.065913 ;Test Accuracy : 79.000000\n",
            "At Iteration : 12 / 45  ; Loss : 1.065913\n",
            "At Iteration : 12 / 45  ;  Train Error : 1.065913 ;Test Accuracy : 80.000000\n",
            "At Iteration : 12 / 45  ; Loss : 1.065913\n",
            "At Iteration : 12 / 45  ;  Train Error : 1.065913 ;Test Accuracy : 81.000000\n",
            "At Iteration : 12 / 45  ; Loss : 1.065913\n",
            "At Iteration : 12 / 45  ;  Train Error : 1.065913 ;Test Accuracy : 82.000000\n",
            "At Iteration : 12 / 45  ; Loss : 1.065913\n",
            "At Iteration : 12 / 45  ;  Train Error : 1.065913 ;Test Accuracy : 83.000000\n",
            "At Iteration : 12 / 45  ; Loss : 1.065913\n",
            "At Iteration : 12 / 45  ;  Train Error : 1.065913 ;Test Accuracy : 83.000000\n",
            "At Iteration : 12 / 45  ; Loss : 1.065913\n",
            "At Iteration : 13 / 45  ;  Train Error : 1.036395 ;Test Accuracy : 81.000000\n",
            "At Iteration : 13 / 45  ; Loss : 1.036395\n",
            "At Iteration : 13 / 45  ;  Train Error : 1.036395 ;Test Accuracy : 79.000000\n",
            "At Iteration : 13 / 45  ; Loss : 1.036395\n",
            "At Iteration : 13 / 45  ;  Train Error : 1.036395 ;Test Accuracy : 80.000000\n",
            "At Iteration : 13 / 45  ; Loss : 1.036395\n",
            "At Iteration : 13 / 45  ;  Train Error : 1.036395 ;Test Accuracy : 79.000000\n",
            "At Iteration : 13 / 45  ; Loss : 1.036395\n",
            "At Iteration : 13 / 45  ;  Train Error : 1.036395 ;Test Accuracy : 79.000000\n",
            "At Iteration : 13 / 45  ; Loss : 1.036395\n",
            "At Iteration : 13 / 45  ;  Train Error : 1.036395 ;Test Accuracy : 81.000000\n",
            "At Iteration : 13 / 45  ; Loss : 1.036395\n",
            "At Iteration : 13 / 45  ;  Train Error : 1.036395 ;Test Accuracy : 82.000000\n",
            "At Iteration : 13 / 45  ; Loss : 1.036395\n",
            "At Iteration : 13 / 45  ;  Train Error : 1.036395 ;Test Accuracy : 82.000000\n",
            "At Iteration : 13 / 45  ; Loss : 1.036395\n",
            "At Iteration : 13 / 45  ;  Train Error : 1.036395 ;Test Accuracy : 83.000000\n",
            "At Iteration : 13 / 45  ; Loss : 1.036395\n",
            "At Iteration : 13 / 45  ;  Train Error : 1.036395 ;Test Accuracy : 83.000000\n",
            "At Iteration : 13 / 45  ; Loss : 1.036395\n",
            "At Iteration : 14 / 45  ;  Train Error : 1.011087 ;Test Accuracy : 81.000000\n",
            "At Iteration : 14 / 45  ; Loss : 1.011087\n",
            "At Iteration : 14 / 45  ;  Train Error : 1.011087 ;Test Accuracy : 80.000000\n",
            "At Iteration : 14 / 45  ; Loss : 1.011087\n",
            "At Iteration : 14 / 45  ;  Train Error : 1.011087 ;Test Accuracy : 80.000000\n",
            "At Iteration : 14 / 45  ; Loss : 1.011087\n",
            "At Iteration : 14 / 45  ;  Train Error : 1.011087 ;Test Accuracy : 80.000000\n",
            "At Iteration : 14 / 45  ; Loss : 1.011087\n",
            "At Iteration : 14 / 45  ;  Train Error : 1.011087 ;Test Accuracy : 80.000000\n",
            "At Iteration : 14 / 45  ; Loss : 1.011087\n",
            "At Iteration : 14 / 45  ;  Train Error : 1.011087 ;Test Accuracy : 81.000000\n",
            "At Iteration : 14 / 45  ; Loss : 1.011087\n",
            "At Iteration : 14 / 45  ;  Train Error : 1.011087 ;Test Accuracy : 82.000000\n",
            "At Iteration : 14 / 45  ; Loss : 1.011087\n",
            "At Iteration : 14 / 45  ;  Train Error : 1.011087 ;Test Accuracy : 83.000000\n",
            "At Iteration : 14 / 45  ; Loss : 1.011087\n",
            "At Iteration : 14 / 45  ;  Train Error : 1.011087 ;Test Accuracy : 84.000000\n",
            "At Iteration : 14 / 45  ; Loss : 1.011087\n",
            "At Iteration : 14 / 45  ;  Train Error : 1.011087 ;Test Accuracy : 84.000000\n",
            "At Iteration : 14 / 45  ; Loss : 1.011087\n",
            "At Iteration : 15 / 45  ;  Train Error : 0.988805 ;Test Accuracy : 82.000000\n",
            "At Iteration : 15 / 45  ; Loss : 0.988805\n",
            "At Iteration : 15 / 45  ;  Train Error : 0.988805 ;Test Accuracy : 80.000000\n",
            "At Iteration : 15 / 45  ; Loss : 0.988805\n",
            "At Iteration : 15 / 45  ;  Train Error : 0.988805 ;Test Accuracy : 81.000000\n",
            "At Iteration : 15 / 45  ; Loss : 0.988805\n",
            "At Iteration : 15 / 45  ;  Train Error : 0.988805 ;Test Accuracy : 80.000000\n",
            "At Iteration : 15 / 45  ; Loss : 0.988805\n",
            "At Iteration : 15 / 45  ;  Train Error : 0.988805 ;Test Accuracy : 80.000000\n",
            "At Iteration : 15 / 45  ; Loss : 0.988805\n",
            "At Iteration : 15 / 45  ;  Train Error : 0.988805 ;Test Accuracy : 82.000000\n",
            "At Iteration : 15 / 45  ; Loss : 0.988805\n",
            "At Iteration : 15 / 45  ;  Train Error : 0.988805 ;Test Accuracy : 83.000000\n",
            "At Iteration : 15 / 45  ; Loss : 0.988805\n",
            "At Iteration : 15 / 45  ;  Train Error : 0.988805 ;Test Accuracy : 83.000000\n",
            "At Iteration : 15 / 45  ; Loss : 0.988805\n",
            "At Iteration : 15 / 45  ;  Train Error : 0.988805 ;Test Accuracy : 84.000000\n",
            "At Iteration : 15 / 45  ; Loss : 0.988805\n",
            "At Iteration : 15 / 45  ;  Train Error : 0.988805 ;Test Accuracy : 84.000000\n",
            "At Iteration : 15 / 45  ; Loss : 0.988805\n",
            "At Iteration : 16 / 45  ;  Train Error : 0.969048 ;Test Accuracy : 82.000000\n",
            "At Iteration : 16 / 45  ; Loss : 0.969048\n",
            "At Iteration : 16 / 45  ;  Train Error : 0.969048 ;Test Accuracy : 81.000000\n",
            "At Iteration : 16 / 45  ; Loss : 0.969048\n",
            "At Iteration : 16 / 45  ;  Train Error : 0.969048 ;Test Accuracy : 81.000000\n",
            "At Iteration : 16 / 45  ; Loss : 0.969048\n",
            "At Iteration : 16 / 45  ;  Train Error : 0.969048 ;Test Accuracy : 81.000000\n",
            "At Iteration : 16 / 45  ; Loss : 0.969048\n",
            "At Iteration : 16 / 45  ;  Train Error : 0.969048 ;Test Accuracy : 81.000000\n",
            "At Iteration : 16 / 45  ; Loss : 0.969048\n",
            "At Iteration : 16 / 45  ;  Train Error : 0.969048 ;Test Accuracy : 82.000000\n",
            "At Iteration : 16 / 45  ; Loss : 0.969048\n",
            "At Iteration : 16 / 45  ;  Train Error : 0.969048 ;Test Accuracy : 83.000000\n",
            "At Iteration : 16 / 45  ; Loss : 0.969048\n",
            "At Iteration : 16 / 45  ;  Train Error : 0.969048 ;Test Accuracy : 84.000000\n",
            "At Iteration : 16 / 45  ; Loss : 0.969048\n",
            "At Iteration : 16 / 45  ;  Train Error : 0.969048 ;Test Accuracy : 84.000000\n",
            "At Iteration : 16 / 45  ; Loss : 0.969048\n",
            "At Iteration : 16 / 45  ;  Train Error : 0.969048 ;Test Accuracy : 84.000000\n",
            "At Iteration : 16 / 45  ; Loss : 0.969048\n",
            "At Iteration : 17 / 45  ;  Train Error : 0.951535 ;Test Accuracy : 82.000000\n",
            "At Iteration : 17 / 45  ; Loss : 0.951535\n",
            "At Iteration : 17 / 45  ;  Train Error : 0.951535 ;Test Accuracy : 81.000000\n",
            "At Iteration : 17 / 45  ; Loss : 0.951535\n",
            "At Iteration : 17 / 45  ;  Train Error : 0.951535 ;Test Accuracy : 81.000000\n",
            "At Iteration : 17 / 45  ; Loss : 0.951535\n",
            "At Iteration : 17 / 45  ;  Train Error : 0.951535 ;Test Accuracy : 81.000000\n",
            "At Iteration : 17 / 45  ; Loss : 0.951535\n",
            "At Iteration : 17 / 45  ;  Train Error : 0.951535 ;Test Accuracy : 81.000000\n",
            "At Iteration : 17 / 45  ; Loss : 0.951535\n",
            "At Iteration : 17 / 45  ;  Train Error : 0.951535 ;Test Accuracy : 82.000000\n",
            "At Iteration : 17 / 45  ; Loss : 0.951535\n",
            "At Iteration : 17 / 45  ;  Train Error : 0.951535 ;Test Accuracy : 83.000000\n",
            "At Iteration : 17 / 45  ; Loss : 0.951535\n",
            "At Iteration : 17 / 45  ;  Train Error : 0.951535 ;Test Accuracy : 84.000000\n",
            "At Iteration : 17 / 45  ; Loss : 0.951535\n",
            "At Iteration : 17 / 45  ;  Train Error : 0.951535 ;Test Accuracy : 85.000000\n",
            "At Iteration : 17 / 45  ; Loss : 0.951535\n",
            "At Iteration : 17 / 45  ;  Train Error : 0.951535 ;Test Accuracy : 85.000000\n",
            "At Iteration : 17 / 45  ; Loss : 0.951535\n",
            "At Iteration : 18 / 45  ;  Train Error : 0.935890 ;Test Accuracy : 83.000000\n",
            "At Iteration : 18 / 45  ; Loss : 0.935890\n",
            "At Iteration : 18 / 45  ;  Train Error : 0.935890 ;Test Accuracy : 81.000000\n",
            "At Iteration : 18 / 45  ; Loss : 0.935890\n",
            "At Iteration : 18 / 45  ;  Train Error : 0.935890 ;Test Accuracy : 82.000000\n",
            "At Iteration : 18 / 45  ; Loss : 0.935890\n",
            "At Iteration : 18 / 45  ;  Train Error : 0.935890 ;Test Accuracy : 81.000000\n",
            "At Iteration : 18 / 45  ; Loss : 0.935890\n",
            "At Iteration : 18 / 45  ;  Train Error : 0.935890 ;Test Accuracy : 81.000000\n",
            "At Iteration : 18 / 45  ; Loss : 0.935890\n",
            "At Iteration : 18 / 45  ;  Train Error : 0.935890 ;Test Accuracy : 82.000000\n",
            "At Iteration : 18 / 45  ; Loss : 0.935890\n",
            "At Iteration : 18 / 45  ;  Train Error : 0.935890 ;Test Accuracy : 83.000000\n",
            "At Iteration : 18 / 45  ; Loss : 0.935890\n",
            "At Iteration : 18 / 45  ;  Train Error : 0.935890 ;Test Accuracy : 84.000000\n",
            "At Iteration : 18 / 45  ; Loss : 0.935890\n",
            "At Iteration : 18 / 45  ;  Train Error : 0.935890 ;Test Accuracy : 85.000000\n",
            "At Iteration : 18 / 45  ; Loss : 0.935890\n",
            "At Iteration : 18 / 45  ;  Train Error : 0.935890 ;Test Accuracy : 85.000000\n",
            "At Iteration : 18 / 45  ; Loss : 0.935890\n",
            "At Iteration : 19 / 45  ;  Train Error : 0.922140 ;Test Accuracy : 83.000000\n",
            "At Iteration : 19 / 45  ; Loss : 0.922140\n",
            "At Iteration : 19 / 45  ;  Train Error : 0.922140 ;Test Accuracy : 82.000000\n",
            "At Iteration : 19 / 45  ; Loss : 0.922140\n",
            "At Iteration : 19 / 45  ;  Train Error : 0.922140 ;Test Accuracy : 82.000000\n",
            "At Iteration : 19 / 45  ; Loss : 0.922140\n",
            "At Iteration : 19 / 45  ;  Train Error : 0.922140 ;Test Accuracy : 82.000000\n",
            "At Iteration : 19 / 45  ; Loss : 0.922140\n",
            "At Iteration : 19 / 45  ;  Train Error : 0.922140 ;Test Accuracy : 82.000000\n",
            "At Iteration : 19 / 45  ; Loss : 0.922140\n",
            "At Iteration : 19 / 45  ;  Train Error : 0.922140 ;Test Accuracy : 83.000000\n",
            "At Iteration : 19 / 45  ; Loss : 0.922140\n",
            "At Iteration : 19 / 45  ;  Train Error : 0.922140 ;Test Accuracy : 83.000000\n",
            "At Iteration : 19 / 45  ; Loss : 0.922140\n",
            "At Iteration : 19 / 45  ;  Train Error : 0.922140 ;Test Accuracy : 84.000000\n",
            "At Iteration : 19 / 45  ; Loss : 0.922140\n",
            "At Iteration : 19 / 45  ;  Train Error : 0.922140 ;Test Accuracy : 85.000000\n",
            "At Iteration : 19 / 45  ; Loss : 0.922140\n",
            "At Iteration : 19 / 45  ;  Train Error : 0.922140 ;Test Accuracy : 85.000000\n",
            "At Iteration : 19 / 45  ; Loss : 0.922140\n",
            "At Iteration : 20 / 45  ;  Train Error : 0.908749 ;Test Accuracy : 83.000000\n",
            "At Iteration : 20 / 45  ; Loss : 0.908749\n",
            "At Iteration : 20 / 45  ;  Train Error : 0.908749 ;Test Accuracy : 82.000000\n",
            "At Iteration : 20 / 45  ; Loss : 0.908749\n",
            "At Iteration : 20 / 45  ;  Train Error : 0.908749 ;Test Accuracy : 82.000000\n",
            "At Iteration : 20 / 45  ; Loss : 0.908749\n",
            "At Iteration : 20 / 45  ;  Train Error : 0.908749 ;Test Accuracy : 82.000000\n",
            "At Iteration : 20 / 45  ; Loss : 0.908749\n",
            "At Iteration : 20 / 45  ;  Train Error : 0.908749 ;Test Accuracy : 82.000000\n",
            "At Iteration : 20 / 45  ; Loss : 0.908749\n",
            "At Iteration : 20 / 45  ;  Train Error : 0.908749 ;Test Accuracy : 83.000000\n",
            "At Iteration : 20 / 45  ; Loss : 0.908749\n",
            "At Iteration : 20 / 45  ;  Train Error : 0.908749 ;Test Accuracy : 84.000000\n",
            "At Iteration : 20 / 45  ; Loss : 0.908749\n",
            "At Iteration : 20 / 45  ;  Train Error : 0.908749 ;Test Accuracy : 84.000000\n",
            "At Iteration : 20 / 45  ; Loss : 0.908749\n",
            "At Iteration : 20 / 45  ;  Train Error : 0.908749 ;Test Accuracy : 85.000000\n",
            "At Iteration : 20 / 45  ; Loss : 0.908749\n",
            "At Iteration : 20 / 45  ;  Train Error : 0.908749 ;Test Accuracy : 85.000000\n",
            "At Iteration : 20 / 45  ; Loss : 0.908749\n",
            "At Iteration : 21 / 45  ;  Train Error : 0.896967 ;Test Accuracy : 83.000000\n",
            "At Iteration : 21 / 45  ; Loss : 0.896967\n",
            "At Iteration : 21 / 45  ;  Train Error : 0.896967 ;Test Accuracy : 82.000000\n",
            "At Iteration : 21 / 45  ; Loss : 0.896967\n",
            "At Iteration : 21 / 45  ;  Train Error : 0.896967 ;Test Accuracy : 82.000000\n",
            "At Iteration : 21 / 45  ; Loss : 0.896967\n",
            "At Iteration : 21 / 45  ;  Train Error : 0.896967 ;Test Accuracy : 82.000000\n",
            "At Iteration : 21 / 45  ; Loss : 0.896967\n",
            "At Iteration : 21 / 45  ;  Train Error : 0.896967 ;Test Accuracy : 82.000000\n",
            "At Iteration : 21 / 45  ; Loss : 0.896967\n",
            "At Iteration : 21 / 45  ;  Train Error : 0.896967 ;Test Accuracy : 83.000000\n",
            "At Iteration : 21 / 45  ; Loss : 0.896967\n",
            "At Iteration : 21 / 45  ;  Train Error : 0.896967 ;Test Accuracy : 84.000000\n",
            "At Iteration : 21 / 45  ; Loss : 0.896967\n",
            "At Iteration : 21 / 45  ;  Train Error : 0.896967 ;Test Accuracy : 84.000000\n",
            "At Iteration : 21 / 45  ; Loss : 0.896967\n",
            "At Iteration : 21 / 45  ;  Train Error : 0.896967 ;Test Accuracy : 85.000000\n",
            "At Iteration : 21 / 45  ; Loss : 0.896967\n",
            "At Iteration : 21 / 45  ;  Train Error : 0.896967 ;Test Accuracy : 85.000000\n",
            "At Iteration : 21 / 45  ; Loss : 0.896967\n",
            "At Iteration : 22 / 45  ;  Train Error : 0.885567 ;Test Accuracy : 84.000000\n",
            "At Iteration : 22 / 45  ; Loss : 0.885567\n",
            "At Iteration : 22 / 45  ;  Train Error : 0.885567 ;Test Accuracy : 82.000000\n",
            "At Iteration : 22 / 45  ; Loss : 0.885567\n",
            "At Iteration : 22 / 45  ;  Train Error : 0.885567 ;Test Accuracy : 83.000000\n",
            "At Iteration : 22 / 45  ; Loss : 0.885567\n",
            "At Iteration : 22 / 45  ;  Train Error : 0.885567 ;Test Accuracy : 82.000000\n",
            "At Iteration : 22 / 45  ; Loss : 0.885567\n",
            "At Iteration : 22 / 45  ;  Train Error : 0.885567 ;Test Accuracy : 82.000000\n",
            "At Iteration : 22 / 45  ; Loss : 0.885567\n",
            "At Iteration : 22 / 45  ;  Train Error : 0.885567 ;Test Accuracy : 83.000000\n",
            "At Iteration : 22 / 45  ; Loss : 0.885567\n",
            "At Iteration : 22 / 45  ;  Train Error : 0.885567 ;Test Accuracy : 84.000000\n",
            "At Iteration : 22 / 45  ; Loss : 0.885567\n",
            "At Iteration : 22 / 45  ;  Train Error : 0.885567 ;Test Accuracy : 85.000000\n",
            "At Iteration : 22 / 45  ; Loss : 0.885567\n",
            "At Iteration : 22 / 45  ;  Train Error : 0.885567 ;Test Accuracy : 85.000000\n",
            "At Iteration : 22 / 45  ; Loss : 0.885567\n",
            "At Iteration : 22 / 45  ;  Train Error : 0.885567 ;Test Accuracy : 86.000000\n",
            "At Iteration : 22 / 45  ; Loss : 0.885567\n",
            "At Iteration : 23 / 45  ;  Train Error : 0.875437 ;Test Accuracy : 84.000000\n",
            "At Iteration : 23 / 45  ; Loss : 0.875437\n",
            "At Iteration : 23 / 45  ;  Train Error : 0.875437 ;Test Accuracy : 83.000000\n",
            "At Iteration : 23 / 45  ; Loss : 0.875437\n",
            "At Iteration : 23 / 45  ;  Train Error : 0.875437 ;Test Accuracy : 83.000000\n",
            "At Iteration : 23 / 45  ; Loss : 0.875437\n",
            "At Iteration : 23 / 45  ;  Train Error : 0.875437 ;Test Accuracy : 82.000000\n",
            "At Iteration : 23 / 45  ; Loss : 0.875437\n",
            "At Iteration : 23 / 45  ;  Train Error : 0.875437 ;Test Accuracy : 82.000000\n",
            "At Iteration : 23 / 45  ; Loss : 0.875437\n",
            "At Iteration : 23 / 45  ;  Train Error : 0.875437 ;Test Accuracy : 83.000000\n",
            "At Iteration : 23 / 45  ; Loss : 0.875437\n",
            "At Iteration : 23 / 45  ;  Train Error : 0.875437 ;Test Accuracy : 84.000000\n",
            "At Iteration : 23 / 45  ; Loss : 0.875437\n",
            "At Iteration : 23 / 45  ;  Train Error : 0.875437 ;Test Accuracy : 85.000000\n",
            "At Iteration : 23 / 45  ; Loss : 0.875437\n",
            "At Iteration : 23 / 45  ;  Train Error : 0.875437 ;Test Accuracy : 86.000000\n",
            "At Iteration : 23 / 45  ; Loss : 0.875437\n",
            "At Iteration : 23 / 45  ;  Train Error : 0.875437 ;Test Accuracy : 86.000000\n",
            "At Iteration : 23 / 45  ; Loss : 0.875437\n",
            "At Iteration : 24 / 45  ;  Train Error : 0.866235 ;Test Accuracy : 84.000000\n",
            "At Iteration : 24 / 45  ; Loss : 0.866235\n",
            "At Iteration : 24 / 45  ;  Train Error : 0.866235 ;Test Accuracy : 83.000000\n",
            "At Iteration : 24 / 45  ; Loss : 0.866235\n",
            "At Iteration : 24 / 45  ;  Train Error : 0.866235 ;Test Accuracy : 83.000000\n",
            "At Iteration : 24 / 45  ; Loss : 0.866235\n",
            "At Iteration : 24 / 45  ;  Train Error : 0.866235 ;Test Accuracy : 82.000000\n",
            "At Iteration : 24 / 45  ; Loss : 0.866235\n",
            "At Iteration : 24 / 45  ;  Train Error : 0.866235 ;Test Accuracy : 82.000000\n",
            "At Iteration : 24 / 45  ; Loss : 0.866235\n",
            "At Iteration : 24 / 45  ;  Train Error : 0.866235 ;Test Accuracy : 83.000000\n",
            "At Iteration : 24 / 45  ; Loss : 0.866235\n",
            "At Iteration : 24 / 45  ;  Train Error : 0.866235 ;Test Accuracy : 84.000000\n",
            "At Iteration : 24 / 45  ; Loss : 0.866235\n",
            "At Iteration : 24 / 45  ;  Train Error : 0.866235 ;Test Accuracy : 85.000000\n",
            "At Iteration : 24 / 45  ; Loss : 0.866235\n",
            "At Iteration : 24 / 45  ;  Train Error : 0.866235 ;Test Accuracy : 86.000000\n",
            "At Iteration : 24 / 45  ; Loss : 0.866235\n",
            "At Iteration : 24 / 45  ;  Train Error : 0.866235 ;Test Accuracy : 86.000000\n",
            "At Iteration : 24 / 45  ; Loss : 0.866235\n",
            "At Iteration : 25 / 45  ;  Train Error : 0.857216 ;Test Accuracy : 84.000000\n",
            "At Iteration : 25 / 45  ; Loss : 0.857216\n",
            "At Iteration : 25 / 45  ;  Train Error : 0.857216 ;Test Accuracy : 83.000000\n",
            "At Iteration : 25 / 45  ; Loss : 0.857216\n",
            "At Iteration : 25 / 45  ;  Train Error : 0.857216 ;Test Accuracy : 83.000000\n",
            "At Iteration : 25 / 45  ; Loss : 0.857216\n",
            "At Iteration : 25 / 45  ;  Train Error : 0.857216 ;Test Accuracy : 83.000000\n",
            "At Iteration : 25 / 45  ; Loss : 0.857216\n",
            "At Iteration : 25 / 45  ;  Train Error : 0.857216 ;Test Accuracy : 83.000000\n",
            "At Iteration : 25 / 45  ; Loss : 0.857216\n",
            "At Iteration : 25 / 45  ;  Train Error : 0.857216 ;Test Accuracy : 84.000000\n",
            "At Iteration : 25 / 45  ; Loss : 0.857216\n",
            "At Iteration : 25 / 45  ;  Train Error : 0.857216 ;Test Accuracy : 84.000000\n",
            "At Iteration : 25 / 45  ; Loss : 0.857216\n",
            "At Iteration : 25 / 45  ;  Train Error : 0.857216 ;Test Accuracy : 85.000000\n",
            "At Iteration : 25 / 45  ; Loss : 0.857216\n",
            "At Iteration : 25 / 45  ;  Train Error : 0.857216 ;Test Accuracy : 86.000000\n",
            "At Iteration : 25 / 45  ; Loss : 0.857216\n",
            "At Iteration : 25 / 45  ;  Train Error : 0.857216 ;Test Accuracy : 86.000000\n",
            "At Iteration : 25 / 45  ; Loss : 0.857216\n",
            "At Iteration : 26 / 45  ;  Train Error : 0.848933 ;Test Accuracy : 84.000000\n",
            "At Iteration : 26 / 45  ; Loss : 0.848933\n",
            "At Iteration : 26 / 45  ;  Train Error : 0.848933 ;Test Accuracy : 83.000000\n",
            "At Iteration : 26 / 45  ; Loss : 0.848933\n",
            "At Iteration : 26 / 45  ;  Train Error : 0.848933 ;Test Accuracy : 83.000000\n",
            "At Iteration : 26 / 45  ; Loss : 0.848933\n",
            "At Iteration : 26 / 45  ;  Train Error : 0.848933 ;Test Accuracy : 83.000000\n",
            "At Iteration : 26 / 45  ; Loss : 0.848933\n",
            "At Iteration : 26 / 45  ;  Train Error : 0.848933 ;Test Accuracy : 83.000000\n",
            "At Iteration : 26 / 45  ; Loss : 0.848933\n",
            "At Iteration : 26 / 45  ;  Train Error : 0.848933 ;Test Accuracy : 84.000000\n",
            "At Iteration : 26 / 45  ; Loss : 0.848933\n",
            "At Iteration : 26 / 45  ;  Train Error : 0.848933 ;Test Accuracy : 85.000000\n",
            "At Iteration : 26 / 45  ; Loss : 0.848933\n",
            "At Iteration : 26 / 45  ;  Train Error : 0.848933 ;Test Accuracy : 85.000000\n",
            "At Iteration : 26 / 45  ; Loss : 0.848933\n",
            "At Iteration : 26 / 45  ;  Train Error : 0.848933 ;Test Accuracy : 86.000000\n",
            "At Iteration : 26 / 45  ; Loss : 0.848933\n",
            "At Iteration : 26 / 45  ;  Train Error : 0.848933 ;Test Accuracy : 86.000000\n",
            "At Iteration : 26 / 45  ; Loss : 0.848933\n",
            "At Iteration : 27 / 45  ;  Train Error : 0.841477 ;Test Accuracy : 84.000000\n",
            "At Iteration : 27 / 45  ; Loss : 0.841477\n",
            "At Iteration : 27 / 45  ;  Train Error : 0.841477 ;Test Accuracy : 83.000000\n",
            "At Iteration : 27 / 45  ; Loss : 0.841477\n",
            "At Iteration : 27 / 45  ;  Train Error : 0.841477 ;Test Accuracy : 83.000000\n",
            "At Iteration : 27 / 45  ; Loss : 0.841477\n",
            "At Iteration : 27 / 45  ;  Train Error : 0.841477 ;Test Accuracy : 83.000000\n",
            "At Iteration : 27 / 45  ; Loss : 0.841477\n",
            "At Iteration : 27 / 45  ;  Train Error : 0.841477 ;Test Accuracy : 83.000000\n",
            "At Iteration : 27 / 45  ; Loss : 0.841477\n",
            "At Iteration : 27 / 45  ;  Train Error : 0.841477 ;Test Accuracy : 84.000000\n",
            "At Iteration : 27 / 45  ; Loss : 0.841477\n",
            "At Iteration : 27 / 45  ;  Train Error : 0.841477 ;Test Accuracy : 85.000000\n",
            "At Iteration : 27 / 45  ; Loss : 0.841477\n",
            "At Iteration : 27 / 45  ;  Train Error : 0.841477 ;Test Accuracy : 85.000000\n",
            "At Iteration : 27 / 45  ; Loss : 0.841477\n",
            "At Iteration : 27 / 45  ;  Train Error : 0.841477 ;Test Accuracy : 86.000000\n",
            "At Iteration : 27 / 45  ; Loss : 0.841477\n",
            "At Iteration : 27 / 45  ;  Train Error : 0.841477 ;Test Accuracy : 86.000000\n",
            "At Iteration : 27 / 45  ; Loss : 0.841477\n",
            "At Iteration : 28 / 45  ;  Train Error : 0.834098 ;Test Accuracy : 85.000000\n",
            "At Iteration : 28 / 45  ; Loss : 0.834098\n",
            "At Iteration : 28 / 45  ;  Train Error : 0.834098 ;Test Accuracy : 83.000000\n",
            "At Iteration : 28 / 45  ; Loss : 0.834098\n",
            "At Iteration : 28 / 45  ;  Train Error : 0.834098 ;Test Accuracy : 83.000000\n",
            "At Iteration : 28 / 45  ; Loss : 0.834098\n",
            "At Iteration : 28 / 45  ;  Train Error : 0.834098 ;Test Accuracy : 83.000000\n",
            "At Iteration : 28 / 45  ; Loss : 0.834098\n",
            "At Iteration : 28 / 45  ;  Train Error : 0.834098 ;Test Accuracy : 83.000000\n",
            "At Iteration : 28 / 45  ; Loss : 0.834098\n",
            "At Iteration : 28 / 45  ;  Train Error : 0.834098 ;Test Accuracy : 84.000000\n",
            "At Iteration : 28 / 45  ; Loss : 0.834098\n",
            "At Iteration : 28 / 45  ;  Train Error : 0.834098 ;Test Accuracy : 85.000000\n",
            "At Iteration : 28 / 45  ; Loss : 0.834098\n",
            "At Iteration : 28 / 45  ;  Train Error : 0.834098 ;Test Accuracy : 86.000000\n",
            "At Iteration : 28 / 45  ; Loss : 0.834098\n",
            "At Iteration : 28 / 45  ;  Train Error : 0.834098 ;Test Accuracy : 86.000000\n",
            "At Iteration : 28 / 45  ; Loss : 0.834098\n",
            "At Iteration : 28 / 45  ;  Train Error : 0.834098 ;Test Accuracy : 86.000000\n",
            "At Iteration : 28 / 45  ; Loss : 0.834098\n",
            "At Iteration : 29 / 45  ;  Train Error : 0.827419 ;Test Accuracy : 85.000000\n",
            "At Iteration : 29 / 45  ; Loss : 0.827419\n",
            "At Iteration : 29 / 45  ;  Train Error : 0.827419 ;Test Accuracy : 84.000000\n",
            "At Iteration : 29 / 45  ; Loss : 0.827419\n",
            "At Iteration : 29 / 45  ;  Train Error : 0.827419 ;Test Accuracy : 84.000000\n",
            "At Iteration : 29 / 45  ; Loss : 0.827419\n",
            "At Iteration : 29 / 45  ;  Train Error : 0.827419 ;Test Accuracy : 83.000000\n",
            "At Iteration : 29 / 45  ; Loss : 0.827419\n",
            "At Iteration : 29 / 45  ;  Train Error : 0.827419 ;Test Accuracy : 83.000000\n",
            "At Iteration : 29 / 45  ; Loss : 0.827419\n",
            "At Iteration : 29 / 45  ;  Train Error : 0.827419 ;Test Accuracy : 84.000000\n",
            "At Iteration : 29 / 45  ; Loss : 0.827419\n",
            "At Iteration : 29 / 45  ;  Train Error : 0.827419 ;Test Accuracy : 85.000000\n",
            "At Iteration : 29 / 45  ; Loss : 0.827419\n",
            "At Iteration : 29 / 45  ;  Train Error : 0.827419 ;Test Accuracy : 86.000000\n",
            "At Iteration : 29 / 45  ; Loss : 0.827419\n",
            "At Iteration : 29 / 45  ;  Train Error : 0.827419 ;Test Accuracy : 87.000000\n",
            "At Iteration : 29 / 45  ; Loss : 0.827419\n",
            "At Iteration : 29 / 45  ;  Train Error : 0.827419 ;Test Accuracy : 87.000000\n",
            "At Iteration : 29 / 45  ; Loss : 0.827419\n",
            "At Iteration : 30 / 45  ;  Train Error : 0.820979 ;Test Accuracy : 85.000000\n",
            "At Iteration : 30 / 45  ; Loss : 0.820979\n",
            "At Iteration : 30 / 45  ;  Train Error : 0.820979 ;Test Accuracy : 84.000000\n",
            "At Iteration : 30 / 45  ; Loss : 0.820979\n",
            "At Iteration : 30 / 45  ;  Train Error : 0.820979 ;Test Accuracy : 84.000000\n",
            "At Iteration : 30 / 45  ; Loss : 0.820979\n",
            "At Iteration : 30 / 45  ;  Train Error : 0.820979 ;Test Accuracy : 83.000000\n",
            "At Iteration : 30 / 45  ; Loss : 0.820979\n",
            "At Iteration : 30 / 45  ;  Train Error : 0.820979 ;Test Accuracy : 83.000000\n",
            "At Iteration : 30 / 45  ; Loss : 0.820979\n",
            "At Iteration : 30 / 45  ;  Train Error : 0.820979 ;Test Accuracy : 84.000000\n",
            "At Iteration : 30 / 45  ; Loss : 0.820979\n",
            "At Iteration : 30 / 45  ;  Train Error : 0.820979 ;Test Accuracy : 85.000000\n",
            "At Iteration : 30 / 45  ; Loss : 0.820979\n",
            "At Iteration : 30 / 45  ;  Train Error : 0.820979 ;Test Accuracy : 86.000000\n",
            "At Iteration : 30 / 45  ; Loss : 0.820979\n",
            "At Iteration : 30 / 45  ;  Train Error : 0.820979 ;Test Accuracy : 87.000000\n",
            "At Iteration : 30 / 45  ; Loss : 0.820979\n",
            "At Iteration : 30 / 45  ;  Train Error : 0.820979 ;Test Accuracy : 87.000000\n",
            "At Iteration : 30 / 45  ; Loss : 0.820979\n",
            "At Iteration : 31 / 45  ;  Train Error : 0.814925 ;Test Accuracy : 85.000000\n",
            "At Iteration : 31 / 45  ; Loss : 0.814925\n",
            "At Iteration : 31 / 45  ;  Train Error : 0.814925 ;Test Accuracy : 84.000000\n",
            "At Iteration : 31 / 45  ; Loss : 0.814925\n",
            "At Iteration : 31 / 45  ;  Train Error : 0.814925 ;Test Accuracy : 84.000000\n",
            "At Iteration : 31 / 45  ; Loss : 0.814925\n",
            "At Iteration : 31 / 45  ;  Train Error : 0.814925 ;Test Accuracy : 83.000000\n",
            "At Iteration : 31 / 45  ; Loss : 0.814925\n",
            "At Iteration : 31 / 45  ;  Train Error : 0.814925 ;Test Accuracy : 83.000000\n",
            "At Iteration : 31 / 45  ; Loss : 0.814925\n",
            "At Iteration : 31 / 45  ;  Train Error : 0.814925 ;Test Accuracy : 84.000000\n",
            "At Iteration : 31 / 45  ; Loss : 0.814925\n",
            "At Iteration : 31 / 45  ;  Train Error : 0.814925 ;Test Accuracy : 85.000000\n",
            "At Iteration : 31 / 45  ; Loss : 0.814925\n",
            "At Iteration : 31 / 45  ;  Train Error : 0.814925 ;Test Accuracy : 86.000000\n",
            "At Iteration : 31 / 45  ; Loss : 0.814925\n",
            "At Iteration : 31 / 45  ;  Train Error : 0.814925 ;Test Accuracy : 87.000000\n",
            "At Iteration : 31 / 45  ; Loss : 0.814925\n",
            "At Iteration : 31 / 45  ;  Train Error : 0.814925 ;Test Accuracy : 87.000000\n",
            "At Iteration : 31 / 45  ; Loss : 0.814925\n",
            "At Iteration : 32 / 45  ;  Train Error : 0.808740 ;Test Accuracy : 85.000000\n",
            "At Iteration : 32 / 45  ; Loss : 0.808740\n",
            "At Iteration : 32 / 45  ;  Train Error : 0.808740 ;Test Accuracy : 84.000000\n",
            "At Iteration : 32 / 45  ; Loss : 0.808740\n",
            "At Iteration : 32 / 45  ;  Train Error : 0.808740 ;Test Accuracy : 84.000000\n",
            "At Iteration : 32 / 45  ; Loss : 0.808740\n",
            "At Iteration : 32 / 45  ;  Train Error : 0.808740 ;Test Accuracy : 84.000000\n",
            "At Iteration : 32 / 45  ; Loss : 0.808740\n",
            "At Iteration : 32 / 45  ;  Train Error : 0.808740 ;Test Accuracy : 84.000000\n",
            "At Iteration : 32 / 45  ; Loss : 0.808740\n",
            "At Iteration : 32 / 45  ;  Train Error : 0.808740 ;Test Accuracy : 84.000000\n",
            "At Iteration : 32 / 45  ; Loss : 0.808740\n",
            "At Iteration : 32 / 45  ;  Train Error : 0.808740 ;Test Accuracy : 85.000000\n",
            "At Iteration : 32 / 45  ; Loss : 0.808740\n",
            "At Iteration : 32 / 45  ;  Train Error : 0.808740 ;Test Accuracy : 86.000000\n",
            "At Iteration : 32 / 45  ; Loss : 0.808740\n",
            "At Iteration : 32 / 45  ;  Train Error : 0.808740 ;Test Accuracy : 87.000000\n",
            "At Iteration : 32 / 45  ; Loss : 0.808740\n",
            "At Iteration : 32 / 45  ;  Train Error : 0.808740 ;Test Accuracy : 87.000000\n",
            "At Iteration : 32 / 45  ; Loss : 0.808740\n",
            "At Iteration : 33 / 45  ;  Train Error : 0.803280 ;Test Accuracy : 85.000000\n",
            "At Iteration : 33 / 45  ; Loss : 0.803280\n",
            "At Iteration : 33 / 45  ;  Train Error : 0.803280 ;Test Accuracy : 84.000000\n",
            "At Iteration : 33 / 45  ; Loss : 0.803280\n",
            "At Iteration : 33 / 45  ;  Train Error : 0.803280 ;Test Accuracy : 84.000000\n",
            "At Iteration : 33 / 45  ; Loss : 0.803280\n",
            "At Iteration : 33 / 45  ;  Train Error : 0.803280 ;Test Accuracy : 84.000000\n",
            "At Iteration : 33 / 45  ; Loss : 0.803280\n",
            "At Iteration : 33 / 45  ;  Train Error : 0.803280 ;Test Accuracy : 84.000000\n",
            "At Iteration : 33 / 45  ; Loss : 0.803280\n",
            "At Iteration : 33 / 45  ;  Train Error : 0.803280 ;Test Accuracy : 85.000000\n",
            "At Iteration : 33 / 45  ; Loss : 0.803280\n",
            "At Iteration : 33 / 45  ;  Train Error : 0.803280 ;Test Accuracy : 85.000000\n",
            "At Iteration : 33 / 45  ; Loss : 0.803280\n",
            "At Iteration : 33 / 45  ;  Train Error : 0.803280 ;Test Accuracy : 86.000000\n",
            "At Iteration : 33 / 45  ; Loss : 0.803280\n",
            "At Iteration : 33 / 45  ;  Train Error : 0.803280 ;Test Accuracy : 87.000000\n",
            "At Iteration : 33 / 45  ; Loss : 0.803280\n",
            "At Iteration : 33 / 45  ;  Train Error : 0.803280 ;Test Accuracy : 87.000000\n",
            "At Iteration : 33 / 45  ; Loss : 0.803280\n",
            "At Iteration : 34 / 45  ;  Train Error : 0.797827 ;Test Accuracy : 85.000000\n",
            "At Iteration : 34 / 45  ; Loss : 0.797827\n",
            "At Iteration : 34 / 45  ;  Train Error : 0.797827 ;Test Accuracy : 84.000000\n",
            "At Iteration : 34 / 45  ; Loss : 0.797827\n",
            "At Iteration : 34 / 45  ;  Train Error : 0.797827 ;Test Accuracy : 84.000000\n",
            "At Iteration : 34 / 45  ; Loss : 0.797827\n",
            "At Iteration : 34 / 45  ;  Train Error : 0.797827 ;Test Accuracy : 84.000000\n",
            "At Iteration : 34 / 45  ; Loss : 0.797827\n",
            "At Iteration : 34 / 45  ;  Train Error : 0.797827 ;Test Accuracy : 84.000000\n",
            "At Iteration : 34 / 45  ; Loss : 0.797827\n",
            "At Iteration : 34 / 45  ;  Train Error : 0.797827 ;Test Accuracy : 85.000000\n",
            "At Iteration : 34 / 45  ; Loss : 0.797827\n",
            "At Iteration : 34 / 45  ;  Train Error : 0.797827 ;Test Accuracy : 85.000000\n",
            "At Iteration : 34 / 45  ; Loss : 0.797827\n",
            "At Iteration : 34 / 45  ;  Train Error : 0.797827 ;Test Accuracy : 86.000000\n",
            "At Iteration : 34 / 45  ; Loss : 0.797827\n",
            "At Iteration : 34 / 45  ;  Train Error : 0.797827 ;Test Accuracy : 87.000000\n",
            "At Iteration : 34 / 45  ; Loss : 0.797827\n",
            "At Iteration : 34 / 45  ;  Train Error : 0.797827 ;Test Accuracy : 87.000000\n",
            "At Iteration : 34 / 45  ; Loss : 0.797827\n",
            "At Iteration : 35 / 45  ;  Train Error : 0.792950 ;Test Accuracy : 85.000000\n",
            "At Iteration : 35 / 45  ; Loss : 0.792950\n",
            "At Iteration : 35 / 45  ;  Train Error : 0.792950 ;Test Accuracy : 84.000000\n",
            "At Iteration : 35 / 45  ; Loss : 0.792950\n",
            "At Iteration : 35 / 45  ;  Train Error : 0.792950 ;Test Accuracy : 84.000000\n",
            "At Iteration : 35 / 45  ; Loss : 0.792950\n",
            "At Iteration : 35 / 45  ;  Train Error : 0.792950 ;Test Accuracy : 84.000000\n",
            "At Iteration : 35 / 45  ; Loss : 0.792950\n",
            "At Iteration : 35 / 45  ;  Train Error : 0.792950 ;Test Accuracy : 84.000000\n",
            "At Iteration : 35 / 45  ; Loss : 0.792950\n",
            "At Iteration : 35 / 45  ;  Train Error : 0.792950 ;Test Accuracy : 85.000000\n",
            "At Iteration : 35 / 45  ; Loss : 0.792950\n",
            "At Iteration : 35 / 45  ;  Train Error : 0.792950 ;Test Accuracy : 85.000000\n",
            "At Iteration : 35 / 45  ; Loss : 0.792950\n",
            "At Iteration : 35 / 45  ;  Train Error : 0.792950 ;Test Accuracy : 86.000000\n",
            "At Iteration : 35 / 45  ; Loss : 0.792950\n",
            "At Iteration : 35 / 45  ;  Train Error : 0.792950 ;Test Accuracy : 87.000000\n",
            "At Iteration : 35 / 45  ; Loss : 0.792950\n",
            "At Iteration : 35 / 45  ;  Train Error : 0.792950 ;Test Accuracy : 87.000000\n",
            "At Iteration : 35 / 45  ; Loss : 0.792950\n",
            "At Iteration : 36 / 45  ;  Train Error : 0.787849 ;Test Accuracy : 85.000000\n",
            "At Iteration : 36 / 45  ; Loss : 0.787849\n",
            "At Iteration : 36 / 45  ;  Train Error : 0.787849 ;Test Accuracy : 84.000000\n",
            "At Iteration : 36 / 45  ; Loss : 0.787849\n",
            "At Iteration : 36 / 45  ;  Train Error : 0.787849 ;Test Accuracy : 84.000000\n",
            "At Iteration : 36 / 45  ; Loss : 0.787849\n",
            "At Iteration : 36 / 45  ;  Train Error : 0.787849 ;Test Accuracy : 84.000000\n",
            "At Iteration : 36 / 45  ; Loss : 0.787849\n",
            "At Iteration : 36 / 45  ;  Train Error : 0.787849 ;Test Accuracy : 84.000000\n",
            "At Iteration : 36 / 45  ; Loss : 0.787849\n",
            "At Iteration : 36 / 45  ;  Train Error : 0.787849 ;Test Accuracy : 85.000000\n",
            "At Iteration : 36 / 45  ; Loss : 0.787849\n",
            "At Iteration : 36 / 45  ;  Train Error : 0.787849 ;Test Accuracy : 86.000000\n",
            "At Iteration : 36 / 45  ; Loss : 0.787849\n",
            "At Iteration : 36 / 45  ;  Train Error : 0.787849 ;Test Accuracy : 86.000000\n",
            "At Iteration : 36 / 45  ; Loss : 0.787849\n",
            "At Iteration : 36 / 45  ;  Train Error : 0.787849 ;Test Accuracy : 87.000000\n",
            "At Iteration : 36 / 45  ; Loss : 0.787849\n",
            "At Iteration : 36 / 45  ;  Train Error : 0.787849 ;Test Accuracy : 87.000000\n",
            "At Iteration : 36 / 45  ; Loss : 0.787849\n",
            "At Iteration : 37 / 45  ;  Train Error : 0.783390 ;Test Accuracy : 85.000000\n",
            "At Iteration : 37 / 45  ; Loss : 0.783390\n",
            "At Iteration : 37 / 45  ;  Train Error : 0.783390 ;Test Accuracy : 84.000000\n",
            "At Iteration : 37 / 45  ; Loss : 0.783390\n",
            "At Iteration : 37 / 45  ;  Train Error : 0.783390 ;Test Accuracy : 84.000000\n",
            "At Iteration : 37 / 45  ; Loss : 0.783390\n",
            "At Iteration : 37 / 45  ;  Train Error : 0.783390 ;Test Accuracy : 84.000000\n",
            "At Iteration : 37 / 45  ; Loss : 0.783390\n",
            "At Iteration : 37 / 45  ;  Train Error : 0.783390 ;Test Accuracy : 84.000000\n",
            "At Iteration : 37 / 45  ; Loss : 0.783390\n",
            "At Iteration : 37 / 45  ;  Train Error : 0.783390 ;Test Accuracy : 85.000000\n",
            "At Iteration : 37 / 45  ; Loss : 0.783390\n",
            "At Iteration : 37 / 45  ;  Train Error : 0.783390 ;Test Accuracy : 86.000000\n",
            "At Iteration : 37 / 45  ; Loss : 0.783390\n",
            "At Iteration : 37 / 45  ;  Train Error : 0.783390 ;Test Accuracy : 86.000000\n",
            "At Iteration : 37 / 45  ; Loss : 0.783390\n",
            "At Iteration : 37 / 45  ;  Train Error : 0.783390 ;Test Accuracy : 87.000000\n",
            "At Iteration : 37 / 45  ; Loss : 0.783390\n",
            "At Iteration : 37 / 45  ;  Train Error : 0.783390 ;Test Accuracy : 87.000000\n",
            "At Iteration : 37 / 45  ; Loss : 0.783390\n",
            "At Iteration : 38 / 45  ;  Train Error : 0.778362 ;Test Accuracy : 85.000000\n",
            "At Iteration : 38 / 45  ; Loss : 0.778362\n",
            "At Iteration : 38 / 45  ;  Train Error : 0.778362 ;Test Accuracy : 84.000000\n",
            "At Iteration : 38 / 45  ; Loss : 0.778362\n",
            "At Iteration : 38 / 45  ;  Train Error : 0.778362 ;Test Accuracy : 84.000000\n",
            "At Iteration : 38 / 45  ; Loss : 0.778362\n",
            "At Iteration : 38 / 45  ;  Train Error : 0.778362 ;Test Accuracy : 84.000000\n",
            "At Iteration : 38 / 45  ; Loss : 0.778362\n",
            "At Iteration : 38 / 45  ;  Train Error : 0.778362 ;Test Accuracy : 84.000000\n",
            "At Iteration : 38 / 45  ; Loss : 0.778362\n",
            "At Iteration : 38 / 45  ;  Train Error : 0.778362 ;Test Accuracy : 85.000000\n",
            "At Iteration : 38 / 45  ; Loss : 0.778362\n",
            "At Iteration : 38 / 45  ;  Train Error : 0.778362 ;Test Accuracy : 86.000000\n",
            "At Iteration : 38 / 45  ; Loss : 0.778362\n",
            "At Iteration : 38 / 45  ;  Train Error : 0.778362 ;Test Accuracy : 86.000000\n",
            "At Iteration : 38 / 45  ; Loss : 0.778362\n",
            "At Iteration : 38 / 45  ;  Train Error : 0.778362 ;Test Accuracy : 87.000000\n",
            "At Iteration : 38 / 45  ; Loss : 0.778362\n",
            "At Iteration : 38 / 45  ;  Train Error : 0.778362 ;Test Accuracy : 87.000000\n",
            "At Iteration : 38 / 45  ; Loss : 0.778362\n",
            "At Iteration : 39 / 45  ;  Train Error : 0.774591 ;Test Accuracy : 85.000000\n",
            "At Iteration : 39 / 45  ; Loss : 0.774591\n",
            "At Iteration : 39 / 45  ;  Train Error : 0.774591 ;Test Accuracy : 84.000000\n",
            "At Iteration : 39 / 45  ; Loss : 0.774591\n",
            "At Iteration : 39 / 45  ;  Train Error : 0.774591 ;Test Accuracy : 84.000000\n",
            "At Iteration : 39 / 45  ; Loss : 0.774591\n",
            "At Iteration : 39 / 45  ;  Train Error : 0.774591 ;Test Accuracy : 84.000000\n",
            "At Iteration : 39 / 45  ; Loss : 0.774591\n",
            "At Iteration : 39 / 45  ;  Train Error : 0.774591 ;Test Accuracy : 84.000000\n",
            "At Iteration : 39 / 45  ; Loss : 0.774591\n",
            "At Iteration : 39 / 45  ;  Train Error : 0.774591 ;Test Accuracy : 85.000000\n",
            "At Iteration : 39 / 45  ; Loss : 0.774591\n",
            "At Iteration : 39 / 45  ;  Train Error : 0.774591 ;Test Accuracy : 86.000000\n",
            "At Iteration : 39 / 45  ; Loss : 0.774591\n",
            "At Iteration : 39 / 45  ;  Train Error : 0.774591 ;Test Accuracy : 86.000000\n",
            "At Iteration : 39 / 45  ; Loss : 0.774591\n",
            "At Iteration : 39 / 45  ;  Train Error : 0.774591 ;Test Accuracy : 87.000000\n",
            "At Iteration : 39 / 45  ; Loss : 0.774591\n",
            "At Iteration : 39 / 45  ;  Train Error : 0.774591 ;Test Accuracy : 87.000000\n",
            "At Iteration : 39 / 45  ; Loss : 0.774591\n",
            "At Iteration : 40 / 45  ;  Train Error : 0.770208 ;Test Accuracy : 86.000000\n",
            "At Iteration : 40 / 45  ; Loss : 0.770208\n",
            "At Iteration : 40 / 45  ;  Train Error : 0.770208 ;Test Accuracy : 85.000000\n",
            "At Iteration : 40 / 45  ; Loss : 0.770208\n",
            "At Iteration : 40 / 45  ;  Train Error : 0.770208 ;Test Accuracy : 85.000000\n",
            "At Iteration : 40 / 45  ; Loss : 0.770208\n",
            "At Iteration : 40 / 45  ;  Train Error : 0.770208 ;Test Accuracy : 84.000000\n",
            "At Iteration : 40 / 45  ; Loss : 0.770208\n",
            "At Iteration : 40 / 45  ;  Train Error : 0.770208 ;Test Accuracy : 84.000000\n",
            "At Iteration : 40 / 45  ; Loss : 0.770208\n",
            "At Iteration : 40 / 45  ;  Train Error : 0.770208 ;Test Accuracy : 85.000000\n",
            "At Iteration : 40 / 45  ; Loss : 0.770208\n",
            "At Iteration : 40 / 45  ;  Train Error : 0.770208 ;Test Accuracy : 86.000000\n",
            "At Iteration : 40 / 45  ; Loss : 0.770208\n",
            "At Iteration : 40 / 45  ;  Train Error : 0.770208 ;Test Accuracy : 86.000000\n",
            "At Iteration : 40 / 45  ; Loss : 0.770208\n",
            "At Iteration : 40 / 45  ;  Train Error : 0.770208 ;Test Accuracy : 87.000000\n",
            "At Iteration : 40 / 45  ; Loss : 0.770208\n",
            "At Iteration : 40 / 45  ;  Train Error : 0.770208 ;Test Accuracy : 87.000000\n",
            "At Iteration : 40 / 45  ; Loss : 0.770208\n",
            "At Iteration : 41 / 45  ;  Train Error : 0.766514 ;Test Accuracy : 86.000000\n",
            "At Iteration : 41 / 45  ; Loss : 0.766514\n",
            "At Iteration : 41 / 45  ;  Train Error : 0.766514 ;Test Accuracy : 85.000000\n",
            "At Iteration : 41 / 45  ; Loss : 0.766514\n",
            "At Iteration : 41 / 45  ;  Train Error : 0.766514 ;Test Accuracy : 85.000000\n",
            "At Iteration : 41 / 45  ; Loss : 0.766514\n",
            "At Iteration : 41 / 45  ;  Train Error : 0.766514 ;Test Accuracy : 84.000000\n",
            "At Iteration : 41 / 45  ; Loss : 0.766514\n",
            "At Iteration : 41 / 45  ;  Train Error : 0.766514 ;Test Accuracy : 84.000000\n",
            "At Iteration : 41 / 45  ; Loss : 0.766514\n",
            "At Iteration : 41 / 45  ;  Train Error : 0.766514 ;Test Accuracy : 85.000000\n",
            "At Iteration : 41 / 45  ; Loss : 0.766514\n",
            "At Iteration : 41 / 45  ;  Train Error : 0.766514 ;Test Accuracy : 86.000000\n",
            "At Iteration : 41 / 45  ; Loss : 0.766514\n",
            "At Iteration : 41 / 45  ;  Train Error : 0.766514 ;Test Accuracy : 86.000000\n",
            "At Iteration : 41 / 45  ; Loss : 0.766514\n",
            "At Iteration : 41 / 45  ;  Train Error : 0.766514 ;Test Accuracy : 87.000000\n",
            "At Iteration : 41 / 45  ; Loss : 0.766514\n",
            "At Iteration : 41 / 45  ;  Train Error : 0.766514 ;Test Accuracy : 87.000000\n",
            "At Iteration : 41 / 45  ; Loss : 0.766514\n",
            "At Iteration : 42 / 45  ;  Train Error : 0.762256 ;Test Accuracy : 86.000000\n",
            "At Iteration : 42 / 45  ; Loss : 0.762256\n",
            "At Iteration : 42 / 45  ;  Train Error : 0.762256 ;Test Accuracy : 85.000000\n",
            "At Iteration : 42 / 45  ; Loss : 0.762256\n",
            "At Iteration : 42 / 45  ;  Train Error : 0.762256 ;Test Accuracy : 85.000000\n",
            "At Iteration : 42 / 45  ; Loss : 0.762256\n",
            "At Iteration : 42 / 45  ;  Train Error : 0.762256 ;Test Accuracy : 84.000000\n",
            "At Iteration : 42 / 45  ; Loss : 0.762256\n",
            "At Iteration : 42 / 45  ;  Train Error : 0.762256 ;Test Accuracy : 84.000000\n",
            "At Iteration : 42 / 45  ; Loss : 0.762256\n",
            "At Iteration : 42 / 45  ;  Train Error : 0.762256 ;Test Accuracy : 85.000000\n",
            "At Iteration : 42 / 45  ; Loss : 0.762256\n",
            "At Iteration : 42 / 45  ;  Train Error : 0.762256 ;Test Accuracy : 86.000000\n",
            "At Iteration : 42 / 45  ; Loss : 0.762256\n",
            "At Iteration : 42 / 45  ;  Train Error : 0.762256 ;Test Accuracy : 87.000000\n",
            "At Iteration : 42 / 45  ; Loss : 0.762256\n",
            "At Iteration : 42 / 45  ;  Train Error : 0.762256 ;Test Accuracy : 87.000000\n",
            "At Iteration : 42 / 45  ; Loss : 0.762256\n",
            "At Iteration : 42 / 45  ;  Train Error : 0.762256 ;Test Accuracy : 87.000000\n",
            "At Iteration : 42 / 45  ; Loss : 0.762256\n",
            "At Iteration : 43 / 45  ;  Train Error : 0.758495 ;Test Accuracy : 86.000000\n",
            "At Iteration : 43 / 45  ; Loss : 0.758495\n",
            "At Iteration : 43 / 45  ;  Train Error : 0.758495 ;Test Accuracy : 85.000000\n",
            "At Iteration : 43 / 45  ; Loss : 0.758495\n",
            "At Iteration : 43 / 45  ;  Train Error : 0.758495 ;Test Accuracy : 85.000000\n",
            "At Iteration : 43 / 45  ; Loss : 0.758495\n",
            "At Iteration : 43 / 45  ;  Train Error : 0.758495 ;Test Accuracy : 84.000000\n",
            "At Iteration : 43 / 45  ; Loss : 0.758495\n",
            "At Iteration : 43 / 45  ;  Train Error : 0.758495 ;Test Accuracy : 84.000000\n",
            "At Iteration : 43 / 45  ; Loss : 0.758495\n",
            "At Iteration : 43 / 45  ;  Train Error : 0.758495 ;Test Accuracy : 85.000000\n",
            "At Iteration : 43 / 45  ; Loss : 0.758495\n",
            "At Iteration : 43 / 45  ;  Train Error : 0.758495 ;Test Accuracy : 86.000000\n",
            "At Iteration : 43 / 45  ; Loss : 0.758495\n",
            "At Iteration : 43 / 45  ;  Train Error : 0.758495 ;Test Accuracy : 87.000000\n",
            "At Iteration : 43 / 45  ; Loss : 0.758495\n",
            "At Iteration : 43 / 45  ;  Train Error : 0.758495 ;Test Accuracy : 87.000000\n",
            "At Iteration : 43 / 45  ; Loss : 0.758495\n",
            "At Iteration : 43 / 45  ;  Train Error : 0.758495 ;Test Accuracy : 87.000000\n",
            "At Iteration : 43 / 45  ; Loss : 0.758495\n",
            "At Iteration : 44 / 45  ;  Train Error : 0.755035 ;Test Accuracy : 86.000000\n",
            "At Iteration : 44 / 45  ; Loss : 0.755035\n",
            "At Iteration : 44 / 45  ;  Train Error : 0.755035 ;Test Accuracy : 85.000000\n",
            "At Iteration : 44 / 45  ; Loss : 0.755035\n",
            "At Iteration : 44 / 45  ;  Train Error : 0.755035 ;Test Accuracy : 85.000000\n",
            "At Iteration : 44 / 45  ; Loss : 0.755035\n",
            "At Iteration : 44 / 45  ;  Train Error : 0.755035 ;Test Accuracy : 84.000000\n",
            "At Iteration : 44 / 45  ; Loss : 0.755035\n",
            "At Iteration : 44 / 45  ;  Train Error : 0.755035 ;Test Accuracy : 84.000000\n",
            "At Iteration : 44 / 45  ; Loss : 0.755035\n",
            "At Iteration : 44 / 45  ;  Train Error : 0.755035 ;Test Accuracy : 85.000000\n",
            "At Iteration : 44 / 45  ; Loss : 0.755035\n",
            "At Iteration : 44 / 45  ;  Train Error : 0.755035 ;Test Accuracy : 86.000000\n",
            "At Iteration : 44 / 45  ; Loss : 0.755035\n",
            "At Iteration : 44 / 45  ;  Train Error : 0.755035 ;Test Accuracy : 87.000000\n",
            "At Iteration : 44 / 45  ; Loss : 0.755035\n",
            "At Iteration : 44 / 45  ;  Train Error : 0.755035 ;Test Accuracy : 87.000000\n",
            "At Iteration : 44 / 45  ; Loss : 0.755035\n",
            "At Iteration : 44 / 45  ;  Train Error : 0.755035 ;Test Accuracy : 87.000000\n",
            "At Iteration : 44 / 45  ; Loss : 0.755035\n",
            "At Iteration : 45 / 45  ;  Train Error : 0.751782 ;Test Accuracy : 86.000000\n",
            "At Iteration : 45 / 45  ; Loss : 0.751782\n",
            "At Iteration : 45 / 45  ;  Train Error : 0.751782 ;Test Accuracy : 85.000000\n",
            "At Iteration : 45 / 45  ; Loss : 0.751782\n",
            "At Iteration : 45 / 45  ;  Train Error : 0.751782 ;Test Accuracy : 85.000000\n",
            "At Iteration : 45 / 45  ; Loss : 0.751782\n",
            "At Iteration : 45 / 45  ;  Train Error : 0.751782 ;Test Accuracy : 84.000000\n",
            "At Iteration : 45 / 45  ; Loss : 0.751782\n",
            "At Iteration : 45 / 45  ;  Train Error : 0.751782 ;Test Accuracy : 84.000000\n",
            "At Iteration : 45 / 45  ; Loss : 0.751782\n",
            "At Iteration : 45 / 45  ;  Train Error : 0.751782 ;Test Accuracy : 85.000000\n",
            "At Iteration : 45 / 45  ; Loss : 0.751782\n",
            "At Iteration : 45 / 45  ;  Train Error : 0.751782 ;Test Accuracy : 86.000000\n",
            "At Iteration : 45 / 45  ; Loss : 0.751782\n",
            "At Iteration : 45 / 45  ;  Train Error : 0.751782 ;Test Accuracy : 87.000000\n",
            "At Iteration : 45 / 45  ; Loss : 0.751782\n",
            "At Iteration : 45 / 45  ;  Train Error : 0.751782 ;Test Accuracy : 88.000000\n",
            "At Iteration : 45 / 45  ; Loss : 0.751782\n",
            "At Iteration : 45 / 45  ;  Train Error : 0.751782 ;Test Accuracy : 88.000000\n",
            "At Iteration : 45 / 45  ; Loss : 0.751782\n",
            "Done!!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}